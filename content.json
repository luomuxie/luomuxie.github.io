{"posts":[{"title":"Shader Billboard","text":"广告牌功能的实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374Shader &quot;Unity Shaders Book/Chapter 11/Billboard&quot; { Properties { _MainTex (&quot;Main Tex&quot;, 2D) = &quot;white&quot; {} _Color (&quot;Color Tint&quot;, Color) = (1, 1, 1, 1) _VerticalBillboarding (&quot;Vertical Restraints&quot;, Range(0, 1)) = 1 } SubShader { // Need to disable batching because of the vertex animation Tags {&quot;Queue&quot;=&quot;Transparent&quot; &quot;IgnoreProjector&quot;=&quot;True&quot; &quot;RenderType&quot;=&quot;Transparent&quot; &quot;DisableBatching&quot;=&quot;True&quot;} Pass { Tags { &quot;LightMode&quot;=&quot;ForwardBase&quot; } ZWrite Off Blend SrcAlpha OneMinusSrcAlpha Cull Off CGPROGRAM #pragma vertex vert #pragma fragment frag #include &quot;Lighting.cginc&quot; sampler2D _MainTex; float4 _MainTex_ST; fixed4 _Color; fixed _VerticalBillboarding; struct a2v { float4 vertex : POSITION; float4 texcoord : TEXCOORD0; }; struct v2f { float4 pos : SV_POSITION; float2 uv : TEXCOORD0; }; v2f vert (a2v v) { v2f o; // Suppose the center in object space is fixed float3 center = float3(0, 0, 0); float3 viewer = mul(unity_WorldToObject,float4(_WorldSpaceCameraPos, 1)); float3 normalDir = viewer - center; normalDir.y =normalDir.y * _VerticalBillboarding; normalDir = normalize(normalDir); float3 upDir = abs(normalDir.y) &gt; 0.999 ? float3(0, 0, 1) : float3(0, 1, 0); float3 rightDir = normalize(cross(upDir, normalDir)); upDir = normalize(cross(normalDir, rightDir)); float3 centerOffs = v.vertex.xyz - center; float3 localPos = center + rightDir * centerOffs.x + upDir * centerOffs.y + normalDir * centerOffs.z; o.pos = UnityObjectToClipPos(float4(localPos, 1)); o.uv = TRANSFORM_TEX(v.texcoord,_MainTex); return o; } fixed4 frag (v2f i) : SV_Target { fixed4 c = tex2D (_MainTex, i.uv); c.rgb *= _Color.rgb; return c; } ENDCG } } FallBack &quot;Transparent/VertexLit&quot;} 使用场景广告牌技术主要用于优化3D场景的性能和渲染效率。它可以应用于各种场景元素，特别是那些距离摄像机较远且对视觉质量要求不高的对象。如： 精灵和粒子系统：广告牌常用于渲染精灵和粒子系统。例如，火焰、烟雾、雨滴和雪花等效果往往使用广告牌技术实现，以确保这些效果始终面向摄像机，同时减少渲染的复杂度。 树木和植被：广告牌技术经常用于渲染远离摄像机的树木和植被。当树木和植被距离摄像机较远时，我们可以用一张包含树木或植被纹理的广告牌来代替复杂的3D模型。这样可以减少渲染的三角面数量，从而提高性能。 角色和道具：在某些情况下，广告牌技术也可以应用于角色和道具的渲染。例如，在游戏中，远离摄像机的非主要角色或小型道具可以用广告牌表示，以降低渲染负担。 背景元素：在3D场景中，广告牌技术可以用于渲染远处的背景元素，例如云朵、山脉和城市天际线等。这些元素通常位于远离摄像机的地方，使用广告牌技术可以节省渲染资源。 实现原理广告牌（Billboarding）技术的实现原理是通过调整3D场景中的二维面片（Quad），使其始终面向摄像机。这使得我们可以在这些面片上贴上纹理（Texture），从而模拟复杂的3D物体或特效。广告牌技术的主要优势在于它可以大幅降低渲染负担，提高性能。 以下是广告牌技术的实现步骤： 创建一个四边形（Quad）：首先，我们需要一个四边形作为广告牌的基本形状。这个四边形通常是一个简单的2D矩形，由两个三角形组成。 面向摄像机：为了使四边形始终面向摄像机，我们需要在顶点着色器（Vertex Shader）中计算一个新的顶点位置。这个新位置需要考虑摄像机的位置和广告牌的中心位置。通过计算四边形中心到摄像机的向量，我们可以得到一个面向摄像机的法线向量。然后，我们可以通过这个法线向量计算出四边形的右向量和上向量，从而构建一个局部坐标系。这个局部坐标系会随着摄像机的移动而自动调整，确保四边形始终面向摄像机。 顶点位置变换：有了这个局部坐标系，我们可以将原始的顶点位置转换为新的顶点位置。这个转换过程通常涉及将顶点位置减去四边形的中心位置，然后使用局部坐标系的基向量进行旋转。最后，我们将旋转后的顶点位置加回四边形的中心位置，得到最终的顶点位置。 纹理贴图：为了在广告牌上显示我们需要的内容，我们需要为四边形分配一个纹理。在片元着色器（Fragment Shader）中，我们可以使用纹理坐标（UV Coordinates）采样纹理，并将纹理颜色与片元颜色相乘，从而实现广告牌的渲染。 通过以上步骤，广告牌技术可以实现在3D场景中的二维面片始终面向摄像机，从而在视觉上模拟复杂的3D物体或特效，同时提高性能。","link":"/2023/04/23/Billboard/"},{"title":"InvertedHullOutlines","text":"原理“Inverted Hull”（反向包围壳）方法的实现原理如下： 在模型的边缘产生轮廓线效果。首先，这个方法创建了一个与原始模型相同的包围壳（hull），但是将其沿着模型的法线方向向外扩展。具体来说，在顶点着色器中，每个顶点的位置被加上沿法线方向扩展的距离，这个距离由轮廓线的厚度参数控制。 在渲染过程中，背面剔除（Cull Front）被应用于扩展后的包围壳。这意味着，只有扩展包围壳的背面（朝向摄像机的一面）会被渲染。原始模型的前面将不受影响。 在渲染扩展包围壳时，片段着色器会使用指定的轮廓线颜色填充背面。这样，在原始模型边缘的地方，轮廓线将被绘制出来。 由于原始模型和扩展包围壳的深度值相近，轮廓线会被绘制在原始模型的边缘，从而实现轮廓线效果。 这种方法通常在许多情况下可以实现轮廓线效果，但在复杂的几何形状、模型法线不一致或遮挡关系较复杂的情况下可能出现不理想的效果。当模型的内部部分被扩展包围壳的背面所遮挡时，可能会在非边缘部分产生轮廓线。 缺点在这个轮廓线Shader中，轮廓线的效果是通过将模型的法线向外推移，然后绘制该模型的背面（Cull Front），从而在原始模型的边缘显示出轮廓线。在大多数情况下，这种方法可以产生较好的效果。然而，在某些情况下，这种方法可能会导致在非边缘部分产生轮廓线。原因有以下几点： 几何形状的复杂性：对于复杂的几何形状，尤其是那些具有很多相互靠近的部分的形状，可能会出现非边缘部分的轮廓线。因为在将顶点沿法线方向推移时，相邻的顶点可能会相互穿越，导致轮廓线在错误的位置出现。 法线方向的不一致：如果模型的法线方向不一致，可能会导致非边缘部分出现轮廓线。例如，如果模型的一部分法线朝向模型内部，而另一部分法线朝向模型外部，当将顶点沿法线方向推移时，可能会导致非边缘部分出现轮廓线。 为了解决这个问题，可以尝试以下方法： 优化模型：优化模型的几何形状，确保相互靠近的部分有足够的间隔，以避免轮廓线在非边缘部分出现。 检查并修复法线：检查模型的法线方向，确保它们是一致的。如果发现问题，可以使用3D建模软件修复法线。 使用不同的轮廓线绘制方法：如果问题仍然存在，可以尝试使用不同的轮廓线绘制方法。例如，您可以使用基于屏幕空间的轮廓线着色器，它是通过计算屏幕空间中的深度差异来绘制轮廓线，这种方法通常能够更准确地在边缘部分绘制轮廓线。然而，这种方法的性能开销可能会更高，因为它需要在屏幕空间进行计算。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107Shader &quot;Tutorial/020_InvertedHull/Surface&quot; { Properties { _Color (&quot;Tint&quot;, Color) = (0, 0, 0, 1) _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; {} _Smoothness (&quot;Smoothness&quot;, Range(0, 1)) = 0 _Metallic (&quot;Metalness&quot;, Range(0, 1)) = 0 [HDR] _Emission (&quot;Emission&quot;, color) = (0,0,0) _OutlineColor (&quot;Outline Color&quot;, Color) = (0, 0, 0, 1) _OutlineThickness (&quot;Outline Thickness&quot;, Range(0,1)) = 0.1 _OutlineMinThickness (&quot;Outline Min Thickness&quot;, Range(0,1)) = 0.001 _OutlineMaxThickness (&quot;Outline Max Thickness&quot;, Range(0,1)) = 0.1 } SubShader { //the material is completely non-transparent and is rendered at the same time as the other opaque geometry Tags{ &quot;RenderType&quot;=&quot;Opaque&quot; &quot;Queue&quot;=&quot;Geometry&quot;} CGPROGRAM #pragma surface surf Standard fullforwardshadows #pragma target 3.0 sampler2D _MainTex; fixed4 _Color; half _Smoothness; half _Metallic; half3 _Emission; //input struct which is automatically filled by unity struct Input { float2 uv_MainTex; }; //the surface shader function which sets parameters the lighting function then uses void surf (Input i, inout SurfaceOutputStandard o) { //read albedo color from texture and apply tint fixed4 col = tex2D(_MainTex, i.uv_MainTex); col *= _Color; o.Albedo = col.rgb; //just apply the values for metalness, smoothness and emission o.Metallic = _Metallic; o.Smoothness = _Smoothness; o.Emission = _Emission; } ENDCG //The second pass where we render the outlines Pass{ Cull Front CGPROGRAM //include useful shader functions #include &quot;UnityCG.cginc&quot; //define vertex and fragment shader #pragma vertex vert #pragma fragment frag //tint of the texture fixed4 _OutlineColor; float _OutlineThickness; float _OutlineMinThickness; float _OutlineMaxThickness; //the object data that's put into the vertex shader struct appdata{ float4 vertex : POSITION; float4 normal : NORMAL; }; //the data that's used to generate fragments and can be read by the fragment shader struct v2f{ float4 position : SV_POSITION; }; //the vertex shader v2f vert(appdata v){ v2f o; float3 objectScale = float3( length(unity_ObjectToWorld._11_21_31), length(unity_ObjectToWorld._12_22_32), length(unity_ObjectToWorld._13_23_33) ); float thickness = lerp(_OutlineMinThickness, _OutlineMaxThickness, _OutlineThickness); float objectSize = length(objectScale) / 3.0; float relativeThickness = thickness * objectSize; // o.position = UnityObjectToClipPos(v.vertex + normalize(v.normal) * _OutlineThickness); o.position = UnityObjectToClipPos(v.vertex + normalize(v.normal) * relativeThickness); return o; } //the fragment shader fixed4 frag(v2f i) : SV_TARGET{ return _OutlineColor; } ENDCG } } FallBack &quot;Standard&quot;} 为什么一定要通过法线外移：123o.position = UnityObjectToClipPos(v.vertex + normalize(v.normal) * _OutlineThickness);//为什么要通过法线外移，不能直接改成： o.position = UnityObjectToClipPos(v.vertex + _OutlineThickness); 使用法线方向来外移顶点是为了确保轮廓线沿着模型的表面扩展。法线表示了模型表面的方向，因此沿着法线移动顶点可以使轮廓线紧贴模型表面。如果直接使用o.position = UnityObjectToClipPos(v.vertex + _OutlineThickness);，这将不会考虑模型的表面方向，而是在模型的每个顶点上添加一个固定的偏移量。 这种方法可能导致轮廓线不再紧贴模型表面，而是在空间中随意偏移。在某些情况下，这可能导致轮廓线出现不正确或不自然的效果。因此，使用法线方向来外移顶点是创建轮廓线效果的更合适方法。","link":"/2023/05/07/InvertedHullOutlines/"},{"title":"LeanrOpenGL1_DrawATriangle","text":"","link":"/2023/07/20/LeanrOpenGL1-DrawATriangle/"},{"title":"Sprite Outlines2","text":"效果如下： 代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899Shader &quot;Tutorial/049_SpriteOutline&quot;{ Properties{ _Color (&quot;Tint&quot;, Color) = (0, 0, 0, 1) _OutlineColor (&quot;OutlineColor&quot;, Color) = (1, 1, 1, 1) _OutlineWidth (&quot;OutlineWidth&quot;, Range(0, 1)) = 1 _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; {} } SubShader{ Tags{ &quot;RenderType&quot;=&quot;Transparent&quot; &quot;Queue&quot;=&quot;Transparent&quot; } Blend SrcAlpha OneMinusSrcAlpha ZWrite off Cull off Pass{ CGPROGRAM #include &quot;UnityCG.cginc&quot; #pragma vertex vert #pragma fragment frag sampler2D _MainTex; float4 _MainTex_ST; float4 _MainTex_TexelSize; fixed4 _Color; fixed4 _OutlineColor; float _OutlineWidth; struct appdata{ float4 vertex : POSITION; float2 uv : TEXCOORD0; fixed4 color : COLOR; }; struct v2f{ float4 position : SV_POSITION; float2 uv : TEXCOORD0; float3 worldPos : TEXCOORD1; fixed4 color : COLOR; }; v2f vert(appdata v){ v2f o; o.position = UnityObjectToClipPos(v.vertex); o.worldPos = mul(unity_ObjectToWorld, v.vertex); o.uv = TRANSFORM_TEX(v.uv, _MainTex); o.color = v.color; return o; } float2 uvPerWorldUnit(float2 uv, float2 space){ float2 uvPerPixelX = abs(ddx(uv)); float2 uvPerPixelY = abs(ddy(uv)); float unitsPerPixelX = length(ddx(space)); float unitsPerPixelY = length(ddy(space)); float2 uvPerUnitX = uvPerPixelX / unitsPerPixelX; float2 uvPerUnitY = uvPerPixelY / unitsPerPixelY; return (uvPerUnitX + uvPerUnitY); } fixed4 frag(v2f i) : SV_TARGET{ //get regular color fixed4 col = tex2D(_MainTex, i.uv); col *= _Color; col *= i.color; float2 sampleDistance = uvPerWorldUnit(i.uv, i.worldPos.xy) * _OutlineWidth; //float2 sampleDistance = _MainTex_TexelSize.xy * _OutlineWidth; //sample directions #define DIV_SQRT_2 0.70710678118 float2 directions[8] = {float2(1, 0), float2(0, 1), float2(-1, 0), float2(0, -1), float2(DIV_SQRT_2, DIV_SQRT_2), float2(-DIV_SQRT_2, DIV_SQRT_2), float2(-DIV_SQRT_2, -DIV_SQRT_2), float2(DIV_SQRT_2, -DIV_SQRT_2)}; //generate border float maxAlpha = 0; for(uint index = 0; index&lt;8; index++){ float2 sampleUV = i.uv + directions[index] * sampleDistance; maxAlpha = max(maxAlpha, tex2D(_MainTex, sampleUV).a); } //apply border col.rgb = lerp(_OutlineColor.rgb, col.rgb, col.a); col.a = max(col.a, maxAlpha); return col; } ENDCG } }} 原理：这种方法用于为纹理创建轮廓或边框效果，特别适用于风格化渲染或突出场景中的某些元素。该过程涉及在UV坐标周围的多个点采样纹理，并使用Alpha通道信息来确定轮廓。以下是该方法的逐步分解： 为目标对象创建一个新的着色器或材质，以便在其上应用轮廓效果。 在着色器中，根据原始UV坐标对纹理进行采样。这可以通过使用类似HLSL中的tex2D或GLSL中的texture2D函数来实现。 为Alpha通道设置阈值，以区分可见和不可见像素。 在原始UV坐标周围定义一个内核或一组相邻点，以便对纹理进行采样。这可以通过为U和V坐标设置偏移量来实现。 遍历相邻点，并在每个点处对纹理进行采样。 将每个样本的Alpha值与阈值进行比较。如果Alpha值高于阈值，则记住找到的最高Alpha值。 遍历所有相邻点后，检查原始像素是否不可见（即其Alpha值低于阈值），并且在相邻像素中找到的最高Alpha值高于阈值。 如果满足这两个条件，则通过将输出像素颜色设置为所需的轮廓颜色（通常为黑色或与原始纹理形成对比的颜色），并将Alpha值设置为1（完全不透明）来填充轮廓。 否则，使用原始纹理颜色和Alpha值作为输出像素。 这种方法将通过检测原始像素及其相邻像素之间的Alpha通道值差异，在纹理的可见部分周围创建轮廓或边框效果。当纹理的Alpha通道中可见和不可见像素之间存在明显区别时，轮廓会更加突出。 4、遍历相邻点，并在每个点处对纹理进行采样。主要通过这句 12345#define DIV_SQRT_2 0.70710678118float2 directions[8] = {float2(1, 0), float2(0, 1), float2(-1, 0), float2(0, -1), float2(DIV_SQRT_2, DIV_SQRT_2), float2(-DIV_SQRT_2, DIV_SQRT_2), float2(-DIV_SQRT_2, -DIV_SQRT_2), float2(DIV_SQRT_2, -DIV_SQRT_2)}; 在片段函数中，我们首先创建一个方向数组，用于存储我们希望进行采样的方向。你可以牺牲一些速度来获得更多的灵活性，通过使用sin和cos函数来获得这些方向，但这取决于你的选择。我选择在8个方向上进行采样，包括四个主要方向以及对角线方向。重要的是，对角线方向也应该有长度1，如果我们只使用(1, 1)，它们的长度将是sqrt(2)（通过勾股定理很容易得到这个结果，即sqrt(1² + 1²)），我们需要将每个分量除以sqrt(2)，即使用1 / sqrt(2)，这样就可以了。 上面的代码定义了一个名为directions的数组，它包含了8个方向。这些方向分别是上、下、左、右以及对角线方向。DIV_SQRT_2是1除以sqrt(2)的结果，用于计算对角线方向的单位向量。这样，我们可以在这8个方向上对纹理进行采样，以实现轮廓效果。 1、计算轮廓宽度1、以纹素大小为缩放1float2 sampleDistance = _MainTex_TexelSize.xy * _OutlineWidth; 把上这句开启： 这句代码是用于计算轮廓宽度的实际采样距离，以纹理坐标（UV坐标）为单位。我们通过将纹理的纹素大小（_MainTex_TexelSize.xy）与轮廓宽度属性（_OutlineWidth）相乘来实现这一点。 _MainTex_TexelSize.xy：这是一个包含纹理的纹素大小（宽度和高度）的二维向量。它表示一个纹素在UV空间中所占的尺寸。_MainTex_TexelSize.x表示一个纹素在U轴上的尺寸，_MainTex_TexelSize.y表示一个纹素在V轴上的尺寸。这个变量是由Unity自动生成的，对应于_MainTex纹理。 _OutlineWidth：这是一个浮点数，表示轮廓的宽度，以纹理像素为单位。这个值可以在Unity的材质面板上调整，范围为0到10。 将这两个值相乘，我们可以得到一个二维向量sampleDistance，它表示轮廓宽度在UV空间中的实际采样距离。这样，在后面的循环中，我们就可以使用这个距离来计算周围采样点的UV坐标，从而实现不同宽度的轮廓效果。 2、以世界空间宽度为缩放1float2 sampleDistance = uvPerWorldUnit(i.uv, i.worldPos.xy) * _OutlineWidth; ​ 只需要获取每个世界距离的uv距离，然后像目前使用纹素大小那样将其与轮廓宽度相乘，那么让我们为此编写一个函数。可以通过屏幕空间偏导数（更为人熟知的ddx，ddy和fwidth）来计算这个值。 偏导数使我们能够获得每个屏幕像素的uv变化以及每个屏幕像素的世界空间位置变化。我们必须获得uv变化的绝对值，以免意外获得负值，同时还要获得世界位置变化的长度，以便在相机旋转时获得正确的距离。 通过这些值，我们可以通过将每像素的uv除以每像素的单位数，得到x和y轴上的每单位uv值。在x和y方向上获取这些值后，我们只需将这两个值相加并返回它。 123456789float2 uvPerWorldUnit(float2 uv, float2 space){ float2 uvPerPixelX = abs(ddx(uv)); float2 uvPerPixelY = abs(ddy(uv)); float unitsPerPixelX = length(ddx(space)); float unitsPerPixelY = length(ddy(space)); float2 uvPerUnitX = uvPerPixelX / unitsPerPixelX; float2 uvPerUnitY = uvPerPixelY / unitsPerPixelY; return (uvPerUnitX + uvPerUnitY);} 这个函数接受两个输入参数：uv（纹理坐标）和space（世界空间位置）。它首先计算每个屏幕像素的uv变化（uvPerPixelX和uvPerPixelY），然后计算每个屏幕像素的世界空间位置变化（unitsPerPixelX和unitsPerPixelY）。接着，我们可以通过将每像素的uv变化除以每像素的世界空间位置变化来计算x和y轴上的每单位uv值（uvPerUnitX和uvPerUnitY）。最后，将这两个值相加并返回结果。 通过这个函数，我们可以根据世界空间宽度计算轮廓宽度，这样一来，当相机旋转或者距离变化时，轮廓宽度将保持一致。 7、使用最大Alpha使判断边沿使用最大Alpha值来判断边缘的方法基于这样一个观察：在边缘处，一个低Alpha值（透明或半透明）的像素周围通常至少有一个较高Alpha值（不透明）的像素。在这种情况下，我们将遍历周围的采样点，并寻找最大的Alpha值。边缘检测的关键在于比较原始像素的Alpha值和周围采样点的最大Alpha值。 以下是整个过程的详细说明： 遍历周围的采样点，并找到最大Alpha值（maxAlpha）。 使用lerp()函数根据原始像素的Alpha值在原始颜色（col.rgb）和轮廓颜色（_OutlineColor.rgb）之间进行插值。当原始像素的Alpha值较低时（接近透明），插值结果将更接近轮廓颜色。 将col.a设置为max(col.a, maxAlpha)。这样，如果原始像素的Alpha值较低（透明或半透明），而周围采样点的最大Alpha值较高（不透明），则边缘处的像素将具有更高的Alpha值。 通过这种方法，我们可以找到边缘，并在边缘处使Alpha值变为不透明。这样一来，即使原始像素的Alpha值较低，轮廓部分仍然可见。这种方法的关键在于比较原始像素的Alpha值和周围采样点的最大Alpha值，从而识别出边缘并在边缘处生成可见的轮廓。","link":"/2023/05/07/Sprite-Outlines2/"},{"title":"PolarCoordinates","text":"什么是极坐标极坐标（Polar coordinates）是一种描述平面上点位置的坐标系统。在极坐标系统中，一个点的位置由它与原点的距离和它与参考方向（通常是正向 x 轴）的夹角来表示。 极坐标系统的坐标表示通常以 (r, θ) 的形式，其中 r 是点到原点的距离（极径），θ 是点与参考方向的夹角（极角）。极径 r 通常是非负数，而极角 θ 则通常用弧度表示，可以是任意实数。 相比之下，笛卡尔坐标系统使用直角坐标表示点的位置，即以水平和垂直的坐标轴（通常是 x 轴和 y 轴）的数值来表示点的位置。 极坐标系统在某些情况下可以更方便地描述点的位置和进行某些操作。例如，极坐标可以更直观地表示圆形、环形、螺旋等几何形状，以及进行旋转、缩放和扭曲等变换操作。在图形学、物理学、工程学等领域，极坐标系统常被用于描述和处理与圆形、圆环、径向对称等相关的问题。 极坐标的转换123456789#ifndef POLAR_COORDINATES#define POLAR_COORDINATESfloat2 toPolar(float2 cartesian){ float distance = length(cartesian); float angle = atan2(cartesian.y, cartesian.x); return float2(angle / UNITY_TWO_PI, distance);}#endif 角度除以2π。这个除法的目的是将角度值归一化，并使其范围从-0.5到0.5，而不是常见的-π到π范围。这种归一化可以使角度在处理中更加方便，特别是在着色器编程或其他常用归一化值的应用中，如纹理坐标的映射等。相比之下，原始的角度范围(-π到π)可能更难以处理和控制。 如果直接根据以上的公式转换uv，会得出以下的渲染效果 123456//the fragment shader functionfixed4 frag (v2f i) : SV_Target { //get polar coordinates float2 uv = toPolar(i.uv); return float4(frac(uv), 0, 1); //test output} 在这里，只能看到1/4的圆。这是因为，正如前面所描述的，是围绕着“中心”计算角度，而在这里中心位于右下角。幸运的是，在笛卡尔空间中移动中心点非常容易，只需在转换之前从每个轴上减去0.5。由于HLSL会自动将标量转换为每个值都设置为该标量的向量，可以直接写作uv - 0.5。这样，空间范围将变为-0.5到0.5，因此让我其乘以2，以便得到-1到1的范围，并完整显示0-1空间。 123456789//the fragment shader functionfixed4 frag (v2f i) : SV_Target { //make input uvs centered and scaled to -1 to 1 i.uv -= 0.5; i.uv *= 2; //get polar coordinates float2 uv = toPolar(i.uv); return float4(frac(uv), 0, 1); //test output} 12345678910111213141516//the fragment shader functionfixed4 frag (v2f i) : SV_Target { //make input uvs centered and scaled to -1 to 1 i.uv -= 0.5; i.uv *= 2; //get polar coordinates float2 uv = toPolar(i.uv); //move discontinuity in coordinates to 0 uv.x = frac(uv.x); //tile Image // uv.x *= 3; // sample the texture and apply tint fixed4 col = tex2D(_MainTex, uv) * _Color; //return the final color to be drawn on screen return col;} 对于整个图像来说，完全的旋转可能会过于夸张并且会导致图像被拉伸,通过将其平铺多次以获得更好的结果，通过将uv.x乘以3，使图像在x轴上重复3次。这样做可以使得图像的纹理在坐标范围内重复出现，从而创建出更丰富的视觉效果。 1uv.x *= 3; 当在极坐标转换后的纹理坐标中，角度值跳跃从-1.5到1.5的时候，会出现奇怪的无缝问题。这是因为在这些像素点上，纹理采样时会根据内部的局部导数判断我们是否在很远的地方查看纹理，并选择较低的mipmap级别。解决这个问题的”正确”方法是自己计算mipmap级别，然后将其传递给tex2Dlod函数,原文提供了另一篇优秀文章的链接，介绍了这个问题的解决方法：https://bgolus.medium.com/distinctive-derivative-differences-cce38d36797b。 另一种解决方法是将这个无缝问题移动到不太明显的地方。在这种情况下，可以只取输出的x坐标的小数部分，因为默认情况下它的范围是-0.5到0.5，经过处理后会变成0到1，而无缝问题就位于第一张图像的起始处，即0度位置。通过这种处理方式，可以将无缝问题的边缘移动到不太明显的位置，从而减少其对图像的影响。 1uv.x = frac(uv.x); 文章参考于：https://www.ronja-tutorials.com/post/053-polar-coordinates/","link":"/2023/06/23/PolarCoordinates/"},{"title":"SpriteOutline","text":"​ 由于项目需求，需要实现一个同一预制体下所有子物体精灵组合外描边的功能 ，如下图的效果： 本来以为是很简单的一个需求，这个网络上应该有很多成熟的方案。然后开始了两周的不断试错及踩坑功能。 方案一踩坑：首先找到的是资源商店里面的这个资源： https://assetstore.unity.com/packages/vfx/shaders/photoshop-like-2d-sprite-outline-stroke-effect-105207?locale=zh-CN 这个方案的原理也很简单，就是遍历子所有子物体，读取象素信息，然后共同按照计算好的区域写入到一个Texture中，最后把Texture赋值给sprite。 这里由此产生了几个问题： 问题1：由于是新new写入的Texture，在项目中会打断图集，DC会成倍产生 问题2：在测试性能中发现场景中的物体超过50个(每个下有三个SpriteRender子物体)电脑上的运行时间直接超过了1s,在查了Profiler后发现是下面这个循环代码很慢。 12345678for (int y = 0; y &lt; height; y++) { for (int x = 0; x &lt; width; x++) { int index = width * y + x; if (pixels [index].a &gt; 0) { texture.SetPixel (x+(int)vo.offset.x , y+(int)vo.offset.y, pixels [index]); } }} 主要是这句 1texture.SetPixel (x+(int)vo.offset.x , y+(int)vo.offset.y, pixels [index]); 查了网上相关资源，建议不要在for里面使用SetPixel方法，建议使用SetPixels32或GetRawTextureData(https://docs.unity3d.com/ScriptReference/Texture2D.GetRawTextureData.html)替代,尝试使用SetPixels32，第一个Sprite的像素信息写入是正常的，但后面写入的像素信息都不正常，想不到相关处理方案优化陷入僵局。 问题3：这个方案处理出来的边沿锯齿问题还是严重，不够平滑，锯齿表现严重，研究了抗锯齿的方案，未能很好的处理这个问题（这个挖个坑，以后研究一下）放大如下图： 对Shader不是很熟悉，也研究了许久也算是一种思路启发，现在贴上： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153// Unity built-in shader source. Copyright (c) 2016 Unity Technologies. MIT license (see license.txt)Shader &quot;Sprites/_OutlinePro&quot;{ Properties { _Size (&quot;Size&quot;, Int) = 1 _BlurSize (&quot;Blur Size&quot;, Int) = 0 _Color (&quot;Color&quot;, Color) = (1,1,1,1) _BlurAlphaMultiplier (&quot;Blur Alpha Multiplier&quot;, Float) = 0.7 _BlurAlphaChoke (&quot;Blur Alpha Choke&quot;, Float) = 1 _AlphaThreshold (&quot;Alpha Threshold&quot;, Float) = 0.05 _Buffer (&quot;Buffer&quot;, Int) = 0 [PerRendererData] _MainTex (&quot;Sprite Texture&quot;, 2D) = &quot;white&quot; {} //[HideInInspector] _Color (&quot;Tint&quot;, Color) = (1,1,1,1) //[MaterialToggle] PixelSnap (&quot;Pixel snap&quot;, Float) = 0 //[HideInInspector] _RendererColor (&quot;RendererColor&quot;, Color) = (1,1,1,1) [HideInInspector] _Flip (&quot;Flip&quot;, Vector) = (1,1,1,1) //[PerRendererData] _AlphaTex (&quot;External Alpha&quot;, 2D) = &quot;white&quot; {} //[PerRendererData] _EnableExternalAlpha (&quot;Enable External Alpha&quot;, Float) = 0 } SubShader { Tags { &quot;Queue&quot; = &quot;Transparent&quot; &quot;IgnoreProjector&quot; = &quot;True&quot; &quot;RenderType&quot; = &quot;Transparent&quot; &quot;PreviewType&quot; = &quot;Plane&quot; &quot;CanUseSpriteAtlas&quot; = &quot;True&quot; } Cull Off Lighting Off ZWrite Off Blend One OneMinusSrcAlpha Pass { CGPROGRAM #pragma vertex SpriteVert #pragma fragment OutlineSpriteFrag //#pragma target 4.0 #pragma multi_compile_instancing //#pragma multi_compile _ PIXELSNAP_ON //#pragma multi_compile _ ETC1_EXTERNAL_ALPHA #include &quot;UnitySprites.cginc&quot; float4 _MainTex_TexelSize; int _Size; int _BlurSize; //float4 _Color; float _BlurAlphaMultiplier; float _BlurAlphaChoke; float _AlphaThreshold; int _Buffer; float2 _inTexcoord; float4 _pixelTexcoord; float _pixelAlpha; int _blurThickness; int _strokeThickness; fixed4 _clearColor; fixed4 _outColor; float Distance(int x1, int y1, int x2, int y2) { int deltaX = x2-x1; int deltaY = y2-x1; int valTemp = deltaX * deltaX + deltaY * deltaY; return rsqrt(valTemp)*valTemp; } float InverseLerp(float a, float b, float value) { return clamp ((value - a) / (b - a), 0, 1); } //是否存在此象素 bool HasPixelAt(int x, int y) { _pixelTexcoord.x = _inTexcoord.x + (x * _MainTex_TexelSize.x); _pixelTexcoord.y = _inTexcoord.y + (y * _MainTex_TexelSize.y); _pixelAlpha = tex2Dlod (_MainTex, _pixelTexcoord).a; return (_pixelAlpha &gt;= _AlphaThreshold); } //这里主要是差值当前像素的透明度，和颜色设置 bool TrySetPixelAt(int x, int y) { if (!HasPixelAt (x, y)) return false; //获得当前透明象素到最近的不透明象素的距离 float pixelDistance = Distance (0, 0, x, y); pixelDistance -= _Buffer; if (pixelDistance &lt;= 0 || pixelDistance &gt; _Size) return true; //当前像素在所在_strokeThickness, _Size间的位置 float distancePercent = InverseLerp (_strokeThickness, _Size, pixelDistance); //distancePercent = lerp (distancePercent, 1 - distancePercent, _InvertBlur); //chokeScalar = lerp (chokeScalar, distancePercent, _InvertBlur); float blurAlphaMultiplier = lerp (_BlurAlphaMultiplier, _BlurAlphaMultiplier / _Size, distancePercent); float blurAlphaChoke = max (0.95, (pixelDistance - _strokeThickness) * _BlurAlphaChoke ) /0.95; float alphaScalar = ceil (saturate (pixelDistance - _strokeThickness)); // Only blur pixels greater than the stroke thickness. float finalColor = _Color.a * blurAlphaMultiplier / blurAlphaChoke; //更新透明度 _outColor.a = lerp (_Color.a,finalColor, alphaScalar); _outColor.rgb = _Color.rgb * _outColor.a; return true; } fixed4 OutlineSpriteFrag(v2f IN) : SV_Target { _inTexcoord = IN.texcoord; //模糊的厚度 _blurThickness = min (_BlurSize, _Size - 1); //线条厚度 _strokeThickness = _Size - _blurThickness; //maxGridRadius = _Size + _Buffer 线条至模糊范围 int i, j, gridSize, dir = -1, maxGridRadius = _Size + _Buffer; for (int gridRadius = 1; gridRadius &lt;= maxGridRadius; gridRadius++) { gridSize = gridRadius*2; j= 0; for (i = 0; i &lt; gridSize; i++) { j += i * dir; dir *= -1; //return false为重叠部分，不填充颜色直接返回颜色，不进入计算 if (TrySetPixelAt (0, 0)) return _clearColor; //对四个方向都做出差值 if (TrySetPixelAt (-gridRadius, j) || TrySetPixelAt (j, gridRadius) || TrySetPixelAt (gridRadius, -j) || TrySetPixelAt (-j, -gridRadius)) return _outColor; } } return _outColor; } ENDCG } }} 方案一总结：由于要使用GetPixels读取像素信息重新生成一个Texture并重新写入，GetPixels过程中会从GPU重新复制一个Texture到CPU中，在内存中会有两份数据同时存在，这个方案合适于当前要显示的数量不多的请况下 更改思路：根据方案一的总结，重新思考了解决方向，舍弃把所有像素写在一张贴图上的想法，直接备份两分，一份不描边，一份描边，描边的放在后面。 由于只用考虑描边功能，感觉应该是挺好实现的。于是有了以下 方案二：在翻github，找到这么一个方案，就是上下左右四个方向，用四个pass分别做偏移最后做一个混合，先贴上代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214// Upgrade NOTE: replaced 'mul(UNITY_MATRIX_MVP,*)' with 'UnityObjectToClipPos(*)'Shader &quot;Sprites/Outline&quot;{ Properties { [PerRendererData] _MainTex (&quot;Sprite Texture&quot;, 2D) = &quot;white&quot; {} _Color (&quot;Tint&quot;, Color) = (1,1,1,1) [MaterialToggle] PixelSnap (&quot;Pixel snap&quot;, Float) = 0 // Add values to determine if outlining is enabled and outline color. [PerRendererData] _OutlineSize (&quot;Outline&quot;, Float) = 0 [PerRendererData] _OutlineColor(&quot;Outline Color&quot;, Color) = (1,1,1,1) } CGINCLUDE #include &quot;UnityCG.cginc&quot; struct appdata_t { float4 vertex : POSITION; float4 color : COLOR; float2 texcoord : TEXCOORD0; }; struct v2f { float4 vertex : SV_POSITION; fixed4 color : COLOR; float2 texcoord : TEXCOORD0; }; fixed4 _Color; v2f vert_outline(appdata_t IN) { v2f OUT; OUT.vertex = UnityObjectToClipPos(IN.vertex); OUT.texcoord = IN.texcoord; OUT.color = IN.color * _Color; #ifdef PIXELSNAP_ON OUT.vertex = UnityPixelSnap (OUT.vertex); #endif return OUT; } sampler2D _MainTex; sampler2D _AlphaTex; float4 _MainTex_TexelSize; //magic var float _OutlineSize; //outline size fixed4 _OutlineColor; // outlie color fixed4 SampleSpriteTexture (float2 uv) { fixed4 color = tex2D (_MainTex, uv); return color; } ENDCG SubShader { Tags { &quot;Queue&quot;=&quot;Transparent&quot; &quot;IgnoreProjector&quot;=&quot;True&quot; &quot;RenderType&quot;=&quot;Transparent&quot; &quot;PreviewType&quot;=&quot;Plane&quot; &quot;CanUseSpriteAtlas&quot;=&quot;True&quot; } Cull Off Lighting Off ZWrite Off Blend One OneMinusSrcAlpha //outline down Pass { Offset 1, 1 CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma shader_feature ETC1_EXTERNAL_ALPHA v2f vert(appdata_t IN) { return vert_outline(IN); } fixed4 frag(v2f IN) : SV_Target { fixed4 texColor = SampleSpriteTexture (IN.texcoord + fixed2(0,_MainTex_TexelSize.y*_OutlineSize)) * IN.color; fixed4 c = _OutlineColor * texColor.a; return c; } ENDCG } //outline up Pass { Offset 1, 1 CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma shader_feature ETC1_EXTERNAL_ALPHA v2f vert(appdata_t IN) { return vert_outline(IN); } fixed4 frag(v2f IN) : SV_Target { fixed4 texColor = SampleSpriteTexture (IN.texcoord + fixed2(0,- _MainTex_TexelSize.y* _OutlineSize)) * IN.color; fixed4 c = _OutlineColor * texColor.a; return c; } ENDCG } //outline left Pass { Offset 1, 1 CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma shader_feature ETC1_EXTERNAL_ALPHA v2f vert(appdata_t IN) { return vert_outline(IN); } fixed4 frag(v2f IN) : SV_Target { fixed4 texColor = SampleSpriteTexture (IN.texcoord + fixed2(_MainTex_TexelSize.x* _OutlineSize,0)) * IN.color; fixed4 c = _OutlineColor * texColor.a; return c; } ENDCG } //outline right Pass { Offset 1, 1 CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma shader_feature ETC1_EXTERNAL_ALPHA v2f vert(appdata_t IN) { return vert_outline(IN); } fixed4 frag(v2f IN) : SV_Target { fixed4 texColor = SampleSpriteTexture (IN.texcoord + fixed2(-_MainTex_TexelSize.x* _OutlineSize,0)) * IN.color; fixed4 c = _OutlineColor * texColor.a; return c; } ENDCG }// Pass { Offset 0, 0 CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma shader_feature ETC1_EXTERNAL_ALPHA v2f vert(appdata_t IN) { v2f OUT; OUT.vertex = UnityObjectToClipPos(IN.vertex); OUT.texcoord = IN.texcoord; OUT.color = IN.color * _Color; #ifdef PIXELSNAP_ON OUT.vertex = UnityPixelSnap (OUT.vertex); #endif return OUT; } fixed4 frag(v2f IN) : SV_Target { fixed4 c = SampleSpriteTexture (IN.texcoord) * IN.color; c.rgb *= c.a; return c; } ENDCG } }} 总结：这个方案思路简单明了，很好理解，但可以看到这直接产生了5个DC，损耗过大，舍去，但也不失为一个方案在此做一个记录。 方案三：通过内收的方式描边，觉得也是个很好的思路，在这里做下记录 这里贴上代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182Shader &quot;Sprites/Outline&quot;{ Properties { [PerRendererData] _MainTex (&quot;Sprite Texture&quot;, 2D) = &quot;white&quot; {} _Color (&quot;Main texture Tint&quot;, Color) = (1,1,1,1) [Header(General Settings)] [MaterialToggle] _OutlineEnabled (&quot;Outline Enabled&quot;, Float) = 1 [MaterialToggle] _ConnectedAlpha (&quot;Connected Alpha&quot;, Float) = 0 [HideInInspector] _AlphaThreshold (&quot;Alpha clean&quot;, Range (0, 1)) = 0 _Thickness (&quot;Width (Max recommended 100)&quot;, float) = 10 [KeywordEnum(Contour, Frame)] _OutlineShape(&quot;Outline shape&quot;, Float) = 0 [KeywordEnum(Inside under sprite, Inside over sprite, Outside)] _OutlinePosition(&quot;Outline Position (Frame Only)&quot;, Float) = 0 _SolidOutline (&quot;Outline Color Base&quot;, Color) = (1,1,1,1) } SubShader { Tags { &quot;Queue&quot;=&quot;Transparent&quot; &quot;IgnoreProjector&quot;=&quot;True&quot; &quot;RenderType&quot;=&quot;Transparent&quot; &quot;PreviewType&quot;=&quot;Plane&quot; &quot;CanUseSpriteAtlas&quot;=&quot;True&quot; } Cull Off Lighting Off ZWrite Off Blend One OneMinusSrcAlpha Pass { CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma exclude_renderers d3d11_9x #include &quot;UnityCG.cginc&quot; struct appdata_t { float4 vertex : POSITION; float4 color : COLOR; float2 texcoord : TEXCOORD0; }; struct v2f { float4 vertex : SV_POSITION; fixed4 color : COLOR; float2 texcoord : TEXCOORD0; }; fixed4 _Color; fixed _Thickness; fixed _OutlineEnabled; fixed _ConnectedAlpha; fixed _OutlineShape; //fixed _OutlineMode; fixed4 _SolidOutline; fixed _Weight; fixed _AlphaThreshold; v2f vert(appdata_t IN) { v2f OUT; OUT.vertex = UnityObjectToClipPos(IN.vertex); OUT.texcoord = IN.texcoord; OUT.color = IN.color * _Color; #ifdef PIXELSNAP_ON OUT.vertex = UnityPixelSnap (OUT.vertex); #endif return OUT; } sampler2D _MainTex; sampler2D _AlphaTex; float _AlphaSplitEnabled; uniform float4 _MainTex_TexelSize; //重新计算UV取样的 fixed4 SampleSpriteTexture (float2 uv) { float2 offsets; offsets = float2(_Thickness * 2, _Thickness * 2); float2 bigsize = float2(_MainTex_TexelSize.z, _MainTex_TexelSize.w); float2 smallsize = float2(_MainTex_TexelSize.z - offsets.x, _MainTex_TexelSize.w - offsets.y); float2 uv_changed = float2 ( uv.x * bigsize.x / smallsize.x - 0.5 * offsets.x / smallsize.x, uv.y * bigsize.y / smallsize.y - 0.5 * offsets.y / smallsize.y ); if(uv_changed.x &lt; 0 || uv_changed.x &gt; 1 || uv_changed.y &lt; 0 || uv_changed.y &gt; 1) { return float4(0, 0, 0, 0); } fixed4 color = tex2D (_MainTex, uv_changed);#if UNITY_TEXTURE_ALPHASPLIT_ALLOWED if (_AlphaSplitEnabled) color.a = tex2D (_AlphaTex, uv).r;#endif //UNITY_TEXTURE_ALPHASPLIT_ALLOWED return color; } //计算是否边为边缘 bool CheckOriginalSpriteTexture (float2 uv) { float thicknessX = _Thickness / _MainTex_TexelSize.z; float thicknessY = _Thickness / _MainTex_TexelSize.w; int steps = 100; float angle_step = 360.0 / steps; float alphaThreshold = _AlphaThreshold / 10; // check if the basic points has an alpha to speed up the process and not use the for loop bool outline = SampleSpriteTexture(uv + fixed2(0, +thicknessY)).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(0, -thicknessY)).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(+thicknessX, 0)).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(-thicknessX, 0)).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(+thicknessX * cos (3.14 / 4), -thicknessY * sin (3.14 / 4))).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(-thicknessX * cos (3.14 / 4), +thicknessY * sin (3.14 / 4))).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(-thicknessX * cos (3.14 / 4), -thicknessY * sin (3.14 / 4))).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(+thicknessX * cos (3.14 / 4), +thicknessY * sin (3.14 / 4))).a &gt; alphaThreshold; if(outline) return outline; for(int i = 0; i &lt; steps; i++) // high number and not a variable to avoid stupid compiler bugs { float angle = i * angle_step * 2 * 3.14 / 360; if( SampleSpriteTexture(uv + fixed2(thicknessX * cos(angle), thicknessY * sin(angle))).a &gt; alphaThreshold) { outline = true; break; } } return outline; } fixed4 frag(v2f IN) : SV_Target { fixed4 c = SampleSpriteTexture (IN.texcoord) * IN.color; c.rgb *= c.a; fixed4 outlineC = fixed4(0, 0, 0, 1); if(_OutlineEnabled != 0) { outlineC = _SolidOutline; if(_ConnectedAlpha != 0) { outlineC.a *= _Color.a; } outlineC.rgb *= outlineC.a; if( c.a == 0 &amp;&amp; CheckOriginalSpriteTexture(IN.texcoord)) { return outlineC; } return c; } return c; } ENDCG } }}","link":"/2022/08/27/SpriteOutline/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2023/06/23/hello-world/"},{"title":"读《高效能人人士的七个习惯》","text":"习惯二：以终为始撰写个人使命宣言清晰地定义个人的核心价值观、目标和目的，并将其表达出来的一种工具。通过撰写个人使命宣言，人们可以明确自己的生活目标、愿景和价值观，并以此为指导在各个领域做出决策和行动。通过表达和想像来加强个人价值观的理解和内化。反复思考和表达自己的核心价值观，并在心中进行反复演练，以达到潜移默化的转变。 个人使命宣言通常涵盖以下方面： 个人价值观和原则：明确自己的核心价值观和道德准则，例如诚实、正直、勇敢等。 长期目标和愿景：设定个人追求的长期目标和愿景，对未来有明确的方向和目标。 贡献和影响力：阐述自己希望通过自己的行为和工作对他人和社会产生的积极影响。 个人使命陈述：将以上内容整合成一个简洁而有力的陈述，概括自己的个人使命和意义。 撰写个人使命宣言有助于个人的自我认知和目标定位，可以提供清晰的方向，使个人在日常生活中更加有目标和意义。它也可以帮助人们更好地理解自己的价值观和优先级，并在面临抉择时做出更明智的决策。 思考：读到这里时，感觉很有意思，在我工作生活中，特别是作为一个前端的程序员，工作，重复的工作占据了生活的大部分时间，当一有时候空闲下来就会感觉到很迷茫，不知道做什么，头脑经过长时间的工作也变得迟钝、很累想不出自己应该做什么。此时这些碎片的空余时间就会被无目地的刷刷论坛和短视频时里面消耗掉了。但与此同时作为一个996的前端工作者，是没有时间或很少会有成块的时间的。所以反复思考，反复演练，以达到潜移默化，对自己时间的见缝插针就变得尤其重要。 练习方式练习表达和内化个人的核心价值观是一个逐渐深化和持续的过程。以下是一些方法和建议，可以帮助开始实践这个过程： 自省和反思：花时间自省，思考自己真正重要的事物和价值观。问自己一些关键问题，例如什么是对你来说最重要的？你希望在生活中实现什么？这些问题可以帮助你更好地理解自己的核心价值观。 撰写个人使命宣言：将你的核心价值观、长期目标和愿景写成一个简洁而有力的陈述。这个宣言可以作为你的指导原则，帮助你在决策和行动中保持一致性。 反复阅读和思考：将个人使命宣言作为参考，反复阅读和思考它的含义和意义。在日常生活中，抽出时间来仔细阅读和思考它，让这些价值观深入你的思维和意识。 想象和演练：在心中想象自己以这些价值观为指导的情景和行为。反复演练这些场景，想象自己如何应对和表现。通过想象和演练，你可以加强自己与这些价值观的联系，逐渐将它们融入到你的行为中。 实践和反馈：在日常生活中积极应用你的核心价值观。将它们应用于决策、行为和与他人的互动中。持续关注自己的实践，并反思自己的行为是否符合你的价值观。从反馈中学习和成长，并不断调整自己的行为。 记住，这个过程需要时间和持续的努力。通过不断地练习和实践，你可以逐渐加深对自己的价值观的理解，让它们在你的生活中起到更大的作用。 根据角色的不同，我们可能会有不同的使命或价值观。一个人在不同的角色中扮演不同的身份，例如作为家庭成员、职业人士、社区成员等，这些角色对应着不同的责任和期望。在每个角色中，你可以思考和界定相应的使命和价值观。例如，作为一个家庭成员，你的使命可能是关爱和支持家人，维系家庭的和谐；作为职业人士，你的使命可能是努力工作，为公司和社会做出贡献；作为社区成员，你的使命可能是参与社区活动，关注社会问题并积极参与改变。 通过对每个角色进行思考和界定，你可以明确每个角色的核心价值观和使命陈述。这有助于你在不同的角色中保持一致性，并更好地履行各个角色所带来的责任和使命。在实践中，要注意不同角色之间的平衡和协调。有时候，不同的角色可能会产生冲突或优先级的竞争，需要灵活处理和权衡。关键是要确保各个角色之间的关系相互支持和促进，使整个生活更加和谐和有意义。 习惯四：双赢思维当谈到双赢思维时，它是指一种心态和方法，旨在寻求和创造双方都能从中受益的解决方案。以下是对双赢思维的总结： 合作而非竞争：双赢思维强调合作和协作，而非单纯的竞争。它鼓励人们以合作的方式与他人合作，寻求共同利益和共同成长，而不是通过竞争争取个人利益。 积极寻求解决方案：双赢思维的关键在于寻求解决方案，让各方都能获得满意的结果。它要求人们放下对抗和争斗的心态，积极探索创造性的解决方案，以满足各方的需求和利益。 尊重和理解他人：双赢思维强调对他人的尊重和理解。它鼓励人们倾听他人的观点和利益，尊重他人的权益和需要，从而建立积极的合作关系。 长期的眼光：双赢思维注重长期的发展和关系。它认识到通过建立良好的合作关系和互相支持，可以实现长期的持续性双赢局面，而不是短期的权宜之计。 创造价值：双赢思维强调创造共同的价值。它鼓励人们思考如何通过合作和协作，为各方带来更大的价值，从而推动共同的成功和成长。 总而言之，双赢思维是一种积极的心态和方法，它通过合作、寻求解决方案、尊重他人、长期发展和创造共同价值，致力于实现各方的共同利益和持续的成功。 如果无法实现双赢，那么放弃是一个可选的选择。这意味着在某些情况下，如果无法找到满足双方利益的解决方案，放弃当前的选择可能会更有益。放弃并不意味着放弃所有目标或牺牲自己的需要，而是指意识到当前的选择或争议不具备双赢的潜力，从而寻找更合适的解决方案或机会。这样做有助于避免陷入僵局、冲突或不健康的关系。 放弃的决策可能涉及一些权衡和考量，例如： 长远利益：评估当前选择是否会对个人或团体的长远利益产生负面影响。如果发现持续追求当前选择会导致不可弥补的损失或伤害，那么放弃可能是更明智的选择。 价值观和原则：将当前选择与自己的价值观和原则进行对比。如果当前选择违背了个人的核心价值观或原则，并且无法找到妥协或调和的方式，那么放弃可能更符合自己的内心需求。 替代机会：评估是否存在更好的替代机会或选择。有时候，放弃当前选择可能为更好的机会或解决方案打开了门，能够带来更大的利益和满足。 需要注意的是，放弃并不是一种逃避责任或避免困难的方式。它是在认识到当前选择无法实现双赢或对个人利益造成不利影响时，做出明智的决策。通过放弃，你为自己创造了更多的机会，寻找更符合自身价值观和目标的路径。 思考这个观念乍一看有点空洞，假大空想感觉，对这些东西泛泛而谈，但似乎没有现实上的操作意义，什么都是理想上的太完美的想当然而以。但细想一下其实这个心态也确实可以运用到生活、工作、家庭中。如： 感情中：感情中是没有输赢的，当然也没有赢输。如果非要争个高低只有两败具伤，大家都不快乐。 工作中：我时常想如果我在公司中做多一点，花的时间多一点，那我的时间是不是就会少一点。但不花心思多一点，工作出来的结果永远都是差强人意，明明可以做到90分的，却只做80分出来自己满意，公司也不满意，甚至影响到别人对本人的判断，这又真的好吗。 等一下，我在公司工作，在工作时间发现了有些地方不完美，去完善它，公司给我了薪资，我做好工作，这本是我的本职上的事情，理所当然的事情啊。 为什么我会纠结呢？我纠结是忘记了什么是第一，什么是第二了。上班时间肯定工作第一，不是吗？ 我的个人使命： 健康第一 家庭第二 保持专注，注重效率，关注当下 去偿试，偿试所能想到的一切，人生不能重来，无所畏惧 保持成长，坚持阅读 与人相处，想其所想，思其所虑","link":"/2023/06/24/%E8%AF%BB%E3%80%8A%E9%AB%98%E6%95%88%E8%83%BD%E4%BA%BA%E4%BA%BA%E5%A3%AB%E7%9A%84%E4%B8%83%E4%B8%AA%E4%B9%A0%E6%83%AF%E3%80%8B/"}],"tags":[{"name":"shader","slug":"shader","link":"/tags/shader/"}],"categories":[{"name":"shader","slug":"shader","link":"/categories/shader/"},{"name":"书籍阅读","slug":"书籍阅读","link":"/categories/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/"}],"pages":[{"title":"categories","text":"","link":"/categories/index.html"}]}