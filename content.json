{"posts":[{"title":"Shader Billboard","text":"广告牌功能的实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374Shader &quot;Unity Shaders Book/Chapter 11/Billboard&quot; { Properties { _MainTex (&quot;Main Tex&quot;, 2D) = &quot;white&quot; {} _Color (&quot;Color Tint&quot;, Color) = (1, 1, 1, 1) _VerticalBillboarding (&quot;Vertical Restraints&quot;, Range(0, 1)) = 1 } SubShader { // Need to disable batching because of the vertex animation Tags {&quot;Queue&quot;=&quot;Transparent&quot; &quot;IgnoreProjector&quot;=&quot;True&quot; &quot;RenderType&quot;=&quot;Transparent&quot; &quot;DisableBatching&quot;=&quot;True&quot;} Pass { Tags { &quot;LightMode&quot;=&quot;ForwardBase&quot; } ZWrite Off Blend SrcAlpha OneMinusSrcAlpha Cull Off CGPROGRAM #pragma vertex vert #pragma fragment frag #include &quot;Lighting.cginc&quot; sampler2D _MainTex; float4 _MainTex_ST; fixed4 _Color; fixed _VerticalBillboarding; struct a2v { float4 vertex : POSITION; float4 texcoord : TEXCOORD0; }; struct v2f { float4 pos : SV_POSITION; float2 uv : TEXCOORD0; }; v2f vert (a2v v) { v2f o; // Suppose the center in object space is fixed float3 center = float3(0, 0, 0); float3 viewer = mul(unity_WorldToObject,float4(_WorldSpaceCameraPos, 1)); float3 normalDir = viewer - center; normalDir.y =normalDir.y * _VerticalBillboarding; normalDir = normalize(normalDir); float3 upDir = abs(normalDir.y) &gt; 0.999 ? float3(0, 0, 1) : float3(0, 1, 0); float3 rightDir = normalize(cross(upDir, normalDir)); upDir = normalize(cross(normalDir, rightDir)); float3 centerOffs = v.vertex.xyz - center; float3 localPos = center + rightDir * centerOffs.x + upDir * centerOffs.y + normalDir * centerOffs.z; o.pos = UnityObjectToClipPos(float4(localPos, 1)); o.uv = TRANSFORM_TEX(v.texcoord,_MainTex); return o; } fixed4 frag (v2f i) : SV_Target { fixed4 c = tex2D (_MainTex, i.uv); c.rgb *= _Color.rgb; return c; } ENDCG } } FallBack &quot;Transparent/VertexLit&quot;} 使用场景广告牌技术主要用于优化3D场景的性能和渲染效率。它可以应用于各种场景元素，特别是那些距离摄像机较远且对视觉质量要求不高的对象。如： 精灵和粒子系统：广告牌常用于渲染精灵和粒子系统。例如，火焰、烟雾、雨滴和雪花等效果往往使用广告牌技术实现，以确保这些效果始终面向摄像机，同时减少渲染的复杂度。 树木和植被：广告牌技术经常用于渲染远离摄像机的树木和植被。当树木和植被距离摄像机较远时，我们可以用一张包含树木或植被纹理的广告牌来代替复杂的3D模型。这样可以减少渲染的三角面数量，从而提高性能。 角色和道具：在某些情况下，广告牌技术也可以应用于角色和道具的渲染。例如，在游戏中，远离摄像机的非主要角色或小型道具可以用广告牌表示，以降低渲染负担。 背景元素：在3D场景中，广告牌技术可以用于渲染远处的背景元素，例如云朵、山脉和城市天际线等。这些元素通常位于远离摄像机的地方，使用广告牌技术可以节省渲染资源。 实现原理广告牌（Billboarding）技术的实现原理是通过调整3D场景中的二维面片（Quad），使其始终面向摄像机。这使得我们可以在这些面片上贴上纹理（Texture），从而模拟复杂的3D物体或特效。广告牌技术的主要优势在于它可以大幅降低渲染负担，提高性能。 以下是广告牌技术的实现步骤： 创建一个四边形（Quad）：首先，我们需要一个四边形作为广告牌的基本形状。这个四边形通常是一个简单的2D矩形，由两个三角形组成。 面向摄像机：为了使四边形始终面向摄像机，我们需要在顶点着色器（Vertex Shader）中计算一个新的顶点位置。这个新位置需要考虑摄像机的位置和广告牌的中心位置。通过计算四边形中心到摄像机的向量，我们可以得到一个面向摄像机的法线向量。然后，我们可以通过这个法线向量计算出四边形的右向量和上向量，从而构建一个局部坐标系。这个局部坐标系会随着摄像机的移动而自动调整，确保四边形始终面向摄像机。 顶点位置变换：有了这个局部坐标系，我们可以将原始的顶点位置转换为新的顶点位置。这个转换过程通常涉及将顶点位置减去四边形的中心位置，然后使用局部坐标系的基向量进行旋转。最后，我们将旋转后的顶点位置加回四边形的中心位置，得到最终的顶点位置。 纹理贴图：为了在广告牌上显示我们需要的内容，我们需要为四边形分配一个纹理。在片元着色器（Fragment Shader）中，我们可以使用纹理坐标（UV Coordinates）采样纹理，并将纹理颜色与片元颜色相乘，从而实现广告牌的渲染。 通过以上步骤，广告牌技术可以实现在3D场景中的二维面片始终面向摄像机，从而在视觉上模拟复杂的3D物体或特效，同时提高性能。","link":"/2023/04/23/Billboard/"},{"title":"CityOfMachinery","text":"Once upon a time, in a distant land, there was a unique city built entirely of machinery(机械). This was not your typical(典型的) city, as it was a living, breathing entity, a testament to the power of biochemistry(生物化学) and the creative composition(构造) of its original founders. In the heart of the city, standing like a principal(主要的) monument, was a bridge(桥) of grand design. Each day, a procession(队伍) of people would cross it, heading towards the city’s core where a giant, influential(有影响力的) gadget(小装置) pulsated, providing the energy that powered the city. Our story centers around one particular resident of this city, a man named John. John was a welder(焊工), a profession of significant importance here. Despite the mechanized city, John had a soft spot for antiques(古董), which he considered a crucial(关键的) connection to the past. John had a remarkable foresight(预见), the ability to see things before they happened. This trait made him an essential part of the city. One day, while working, he suddenly felt restless(不安的). He looked at the gadget and noticed its motion(运动) was deteriorating(恶化). He couldn’t just stand by and tolerate(忍受) this, it could lead to disaster. He swiftly made his way to the bridge. To his surprise, he noticed the residents moving in an orderly fashion, each with a punctual(准时的) pace, oblivious to the impending danger. He saw the city’s mayor, a woman known for her decisive(果断的) nature and fluent(流利的) speeches. She wore a bitter(痛苦的) grin(咧嘴笑), obviously something was amiss. John rushed up to her, “We need to shut the gadget down. The city is about to explode(爆炸)!” The mayor was taken aback, “John, are you sure about this?” He nodded, “I have no concrete proof, but I’ve never been wrong before.” The mayor was not known to be an individual who would easily swallow(轻易接受) such news. She consulted the city’s database(数据库), which was designed to cater(满足) to all their needs. Yet, it showed no signs of danger. John confessed(承认), “The database wouldn’t pick it up. It’s something I can feel.” Doubt clouded the mayor’s eyes, but she knew John’s reputation. With a decisive tone(语气), she ordered the shutdown of the gadget, “We’ll assume(假设) you’re right, John.” He could see she was ashamed(羞愧的) for not noticing the signs herself. But there was no time to dwell on that. She initiated the draft(草案) of the sanction(制裁), a civil(文明的) process of the city, which included a series of coded commands. They hurriedly input the codes, the gadget slowly humming down to a halt. Meanwhile, outside the city, a storm was brewing. A hurricane(飓风) was approaching, threatening to consume(消耗) them all. But the city’s people were not worried. The city had survived such calamities before, and they retained(保留) the belief in their protective barriers. But there was one thing they hadn’t counted on. With the gadget down, the city’s barriers were weakening. As the storm hit, a powerful wind sucked(吸入) up a lonely pint(品脱) of water from the nearby river, growing into a colossal wave. The barriers crumbled. John’s eyes widened as the wave towered over them. He felt a chill run down his spine. Then he noticed something. His bride(新娘) to be, a woman of immense beauty and courage, was standing at the latter(后面的) end of the bridge, looking at him. Time seemed to slow. As the wave was about to crash onto the city, he saw her extend her hand towards him. He ran, pushing past the crowd, violating(违反) the city’s rules in his desperation. As he reached her, he grasped(抓住) her hand. They both knew they couldn’t outrun the wave. But at least they were together. The wave hit, the city was flooded, and the world around them seemed to crumble. But they held on to each other, standing firm against the disaster. And then, it was over. The city had been severely damaged, but it still stood. The people, though shaken, survived. In the aftermath, the editorial(社论) office of the city’s main newspaper decided to celebrate their survival. They issued a special issue detailing John’s heroic actions. They praised his foresight and his decision to shut down the gadget, actions which saved many lives. The city began the process of rebuilding. They started with the machinery, fixing and irrigating(灌溉) the vital systems. The ordeal had brought a change in them. They had learned the importance of being in touch with their instincts, something they had forgotten in their relentless pursuit of technology. Hence(因此), the story of John and his city serves as a reminder to us all, a tale of courage and resilience against overwhelming odds. The city of machinery may have faltered, but it did not fail, and it would rise again, stronger than ever. It was a testament to the indomitable spirit of its people and their ability to adapt and overcome any challenge.","link":"/2023/07/29/CityOfMachinery/"},{"title":"DeterminationInTheGarage","text":"In a mature(成熟的) city, nestled amongst the pine(松树) trees, sat a small garage(车库). It was not your ordinary garage. For it was a place of unusual determination(决心) and an incubator for bizarre(奇怪的) yet coherent(一致的) ideas, founded by a group of minority(少数族群) inventors who derived(得出) their inspiration from their ancestors(祖先) and the tales of their deeds(行为). The leader of this group was a man named Samuel. Samuel was a man of immense imagination(想象力). He had a knack for finding loopholes(漏洞) in existing technology, which was reflected in the custom(定制的) inventions that flowed(流动) from their garage, each marked with Samuel’s unique description(描述). One day, they were visited by a solemn(庄重的) man named Gerald. Gerald was a representative of a big firm(公司) that wanted to invest in their technology. But there was a catch. Gerald wanted them to change their approach and make it more consistent(一致的) with the industry’s standard terminology(术语) and infrastructure(基础设施). The group was in a bind. They needed the financial reinforcement(增援) to sustain(维持) their work. Still, they were not willing to lose their unique touch. They called for a thorough(彻底的) discussion. They sat around a big table, the diagram(图表) of their latest invention laid out. The atmosphere was as tense as a rook(秃鹫) perched on a fence(围栏) overlooking its prey. Their conversation was interrupted by a sudden noise. A damn(该死的) faulty(有故障的) helicopter(直升机) was causing a raucous outside. They went out to check, each of them grabbing a towel(毛巾) to protect themselves from the dust being kicked up. Amid the chaos, they saw a beggar(乞丐) seeking shelter from the dust storm. They invited him in. In the comfort of the garage, the beggar noticed their design. His eyes lit up, and he asked if he could add something. He took a piece of chalk and began to draw on their blueprint. It was a bizarre and unexpected moment, a true coincidence(巧合). Yet they let him proceed. The beggar turned out to be a retired biology(生物学) professor. His name was Howard, and he had dedicated his life to the study of a rare desert(沙漠) species, the dwarf(矮小的) desert lizard. He pointed out a mechanism the lizards used to regulate their body temperature. He suggested integrating that concept into their design. The group was taken aback. Samuel decided to put the proposal into a test. They spent the next weeks implementing the changes, the hum of their machines echoing like a chorus(合唱) in the garage. They were ready to present their revised design to Gerald. The changes had indeed brought about a remarkable improvement. Gerald was impressed, and he agreed to fund their project, proclaiming(宣布) their invention as a groundbreaking feat. But their journey was far from smooth. They faced a significant setback(挫折) when their prototype failed during a test run. Their hopes seemed to wane like a herd(群) of deer retreating into the woods. Yet, they did not give up. They chose to persevere(坚持下去). Samuel motivated his team, “We need to turn this setback into a step forward.” They worked relentlessly, through nights and days. Their hands were dyed(染色) with grease and dirt, but their spirit never wavered. The sounds of the tools chopping(砍) and clanking, the hum of the machines, and the determination in their eyes, created a picturesque(如画的) scene. They finally managed to hatch(孵化) a perfect prototype. The news spread like a wildfire. The local dairy(奶制品) farmer, who was once skeptical of their work, felt obliged(有义务的) to congratulate them. The group felt a sense of accomplishment. They were no longer the cursed(被诅咒的) inventors working in a small garage; they had become the town’s pride. As a bonus(奖金), the editorial(社论) team of the city’s newspaper decided to feature their story. They celebrated their determination and the sheer will to overcome their challenges. They were no longer just a bunch of inventors working in a garage; they were now an inspirational story for their city and a beacon of hope for young inventors everywhere. A year later, on a calm summer evening, they all gathered around a bonfire. Samuel raised a toast to their success and the paw(爪子) print of the desert lizard etched onto the machine, a token of their fateful encounter with the beggar who turned out to be their savior. As the flames crackled, they could almost see the ghost(幽灵) of their past selves, toiling away in the garage. They had achieved their dream, not by following the aggressive(侵略性的) and ruthless methods of the industry but by executing(执行) their ideas with a firm belief in their unique approach. They had staked(赌注) their all and emerged victorious. They stood as a testament to the power of perseverance and imagination, demonstrating that even the most significant obstacles could be overcome with determination and a bit of luck. Their story served as a reminder to all inventors, to not get dizzy(眩晕) with success, but to continue pushing boundaries, to never stop exploring, to keep the spark of creativity alive. And thus, they became the guardians of their city, the protectors of its creative spirit, and the heroes of their own incredible tale.","link":"/2023/07/29/DeterminationInTheGarage/"},{"title":"LeanrOpenGL2-Texture","text":"基本概念:纹理是一种可以应用到模型表面的图像数据。通过UV坐标映射，纹理的像素被映射到3D模型的表面 UV映射将纹理映射到对象上的过程称为纹理映射或UV映射。在这个过程中，模型的每个顶点都会分配一个UV坐标，这些坐标对应于纹理图像上的位置。UV是二维纹理坐标的名称，其中U是水平方向，V是垂直方向。UV坐标的U方向从左到右，V方向从下到上。因此，原点（0,0）位于纹理的左下角，而（1,1）则位于右上角。 环绕模式纹理的环绕模式决定了当UV坐标超出0到1的范围时会发生什么。常见的环绕模式包括： Clamp：UV坐标被限制在0到1的范围内。 Repeat：纹理在UV坐标超出范围时重复。 Mirror：纹理在UV坐标超出范围时镜像。 纹理过滤GL_LINEAR（也叫线性过滤）Linear Filtering是一种纹理过滤方法，用于确定如何在纹理映射到3D对象时对纹理像素进行插值。当纹理被映射到比其本身分辨率更大或更小的表面时，将需要确定如何对这些像素进行插值以适应新的空间。Linear Filtering正是用于此目的的一种技术。 如何工作Linear Filtering通过计算纹理坐标附近的四个像素的加权平均值来工作。权重基于纹理坐标与每个像素中心之间的距离。 放大（Magnification）: 当纹理被映射到比其自身更大的表面时，Linear Filtering会考虑最接近所需纹理坐标的四个像素，并计算它们的加权平均值。结果是一个平滑的过渡，没有突然的颜色变化。 缩小（Minification）: 当纹理被映射到比其自身更小的表面时，情况更为复杂。简单地使用最近的四个像素可能会导致明显的混叠和视觉伪影。因此，缩小时通常使用Mipmap技术，其中存储了不同分辨率的纹理版本。然后使用Linear Filtering在相应Mipmap级别的像素之间进行插值。 优点与缺点优点: 产生更平滑和自然的视觉效果。 减少了锯齿和像素化的外观。 缺点: 计算上稍微复杂一些，可能比使用点过滤（Point Filtering）更消耗资源。 在某些情况下，可能会导致纹理显得过于模糊。 总之，Linear Filtering是一种常用的纹理过滤技术，特别适用于需要平滑渲染和避免像素化效果的场景。不过，它可能不适合所有应用，特别是当资源有限或目标是保留更粗糙、像素化的外观时。 GL_NEAREST（也叫邻近过滤）GL_NEAREST是OpenGL中的一种纹理过滤方法，也称为”最近邻过滤”或”点过滤”。当纹理被映射到比其自身分辨率更大或更小的表面时，GL_NEAREST会选择最近的纹理坐标对应的纹理像素。 在放大(Magnification)的情况下，GL_NEAREST会返回最接近所需纹理坐标的纹理像素。这种简单的插值方法可能会导致像素化的外观，特别是当纹理被显著放大时。 在缩小(Minification)的情况下，GL_NEAREST会选择最接近所需纹理坐标的纹理像素。这可能会导致混叠（Aliasing）的问题，因为许多纹理像素可能会被忽略，特别是当纹理被显著缩小时。 优点 这种过滤方法的一个优点是，它的性能开销非常小，因为它只需要访问一个纹理像素。 缺点 然而，这种方法的缺点是，它可能会产生较差的图像质量，特别是在纹理被显著缩小或放大的情况下。 因此，GL_NEAREST更适合用于需要快速渲染和不需要高分辨率纹理的场景。 下图是从GL_LINEAR转到GL_NEAREST 纹理单元在OpenGL中，纹理单元是一种硬件资源，用于管理纹理的读取和采样。当在渲染过程中使用多个纹理时，纹理单元允许在一个shader中同时访问多个纹理。 每个纹理单元可以被视为一个纹理的插槽，允许你将纹理绑定到该插槽并通过shader访问它。一个典型的现代GPU可能会有多达16个或更多的纹理单元。 在Unity的Shader语言（HLSL/CG）中，可以通过sampler2D类型来定义一个采样器，并使用内置函数如tex2D与指定的纹理坐标一起，从纹理中采样颜色。 在OpenGL GLSL中，你可以使用sampler2D、sampler3D等类型，并使用如texture函数来从纹理中采样颜色。","link":"/2023/08/03/LeanrOpenGL2-Texture/"},{"title":"LeanrOpenGL1_DrawATriangle","text":"绘制一个三角形在OpenGL中是一个基本操作，，并假设已经设置了一个GLFW窗口和GLAD进行OpenGL的加载。 1. 定义三角形的顶点定义三角形的三个顶点。下面是一个标准化设备坐标（Normalized Device Coordinates，NDC）中的三角形 12345float vertices[] = { -0.5f, -0.5f, 0.0f, // 左下角 0.5f, -0.5f, 0.0f, // 右下角 0.0f, 0.5f, 0.0f // 顶部}; 2. 创建顶点缓冲对象 (VBO) 和顶点数组对象 (VAO)VBO（Vertex Buffer Object）VBO是一个缓冲对象，用于在GPU上存储顶点数据。这些数据可以包括顶点的位置、颜色、法线、纹理坐标等。通过使用VBO，可以有效地将大量数据发送到GPU，并在图形管道中使用它们。当需要渲染几何体时，VBO允许GPU直接访问存储在显存中的数据，从而提供更快的性能。 在OpenGL中，VBO通常与GL_ARRAY_BUFFER目标一起使用，并通过以下方式创建和管理： glGenBuffers生成一个新的缓冲ID。 glBindBuffer绑定该缓冲ID。 glBufferData`或其他类似函数用于填充数据。 VAO（Vertex Array Object）VAO是一个对象，用于存储所有关于顶点属性的配置和与顶点缓冲对象（VBO）的关联。这意味着VAO存储了VBO的绑定信息和顶点属性指针配置。 VAO的优点是可以使用单个调用glBindVertexArray快速切换不同的顶点数据配置。这使得在相同的渲染循环中绘制具有不同顶点属性配置的多个对象更为容易和高效。 VAO本身并不存储任何顶点或索引数据。这些数据是存储在VBO和EBO中的。VAO更像是一个封装了如何从这些缓冲区读取数据的规则和设置的对象。 以下是创建和管理VAO的常用函数： glGenVertexArrays生成一个新的VAO ID。 glBindVertexArray绑定该VAO。 glVertexAttribPointer用于配置顶点属性。 VBO和VAO总结 VBO用于在GPU上存储顶点数据，如顶点的位置、颜色等。 VAO存储有关顶点属性配置和VBO关联的所有信息。 当绑定一个VAO并发起一个绘制调用时（比如glDrawArrays或glDrawElements），OpenGL会根据VAO中存储的状态配置来从相关联的VBO和/或EBO中获取数据。 VAO本身并不存储任何顶点或索引数据。这些数据是存储在VBO和EBO中的。VAO更像是一个封装了如何从这些缓冲区读取数据的规则和设置的对象。 这两者结合使用，使得组织和渲染具有复杂顶点属性的几何体变得更加高效和组织化。 首先，你需要创建一个顶点缓冲对象 (VBO) 来存储三角形的顶点数据，并创建一个顶点数组对象 (VAO) 来保存顶点属性配置。 123unsigned int VBO, VAO;glGenVertexArrays(1, &amp;VAO);glGenBuffers(1, &amp;VBO); 3. 绑定和配置VBO和VAO将顶点数据上传到GPU，并配置顶点属性。 1234567891011121314// 绑定和配置VAOglBindVertexArray(VAO);// 绑定VBO并将顶点数据上传到GPUglBindBuffer(GL_ARRAY_BUFFER, VBO);glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW);// 配置顶点属性glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0);glEnableVertexAttribArray(0);// 解绑glBindBuffer(GL_ARRAY_BUFFER, 0);glBindVertexArray(0); GL_ARRAY_BUFFERGL_ARRAY_BUFFER是OpenGL中的一个缓冲目标，通常与顶点缓冲对象（VBO）一起使用。当你在OpenGL中创建和操作缓冲对象时，你需要指定缓冲对象的类型或“目标”。GL_ARRAY_BUFFER就是这样的一个目标，专门用于顶点属性数据。 详细解释 GL_ARRAY_BUFFER: 这个目标用于存储顶点属性，如顶点位置、颜色、法线、纹理坐标等。当你使用如下命令绑定一个缓冲对象时： 1glBindBuffer(GL_ARRAY_BUFFER, bufferID); 你正在告诉OpenGL，后续的缓冲对象操作（例如，使用glBufferData上传数据）将影响与GL_ARRAY_BUFFER目标关联的缓冲对象。 绑定和解绑: 一旦你将缓冲对象绑定到GL_ARRAY_BUFFER，你可以进行许多操作，如上传数据、更改缓冲属性等。当你完成后，你可以通过将0传递给glBindBuffer来解绑缓冲对象： 1glBindBuffer(GL_ARRAY_BUFFER, 0); 为什么使用GL_ARRAY_BUFFEROpenGL定义了许多不同类型的缓冲目标，每个目标都用于特定的数据类型和操作。GL_ARRAY_BUFFER是其中之一，用于管理和使用顶点属性数据。其他缓冲目标可能用于索引数据（GL_ELEMENT_ARRAY_BUFFER）或其他特定用途。 通过使用GL_ARRAY_BUFFER等目标，OpenGL可以更好地理解如何使用数据，从而可能进行某些优化，同时也有助于更清晰地组织代码和理解数据的用途。 上传顶点数据1glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); 这行代码将顶点数据从CPU内存上传到GPU显存。其中： GL_ARRAY_BUFFER：告诉OpenGL我们正在使用的缓冲类型。 sizeof(vertices)：定义了要上传的数据的大小（以字节为单位）。 vertices：是一个指向要上传的顶点数据的指针。 GL_STATIC_DRAW：这个标志提供了一些关于如何使用这些数据的提示。在这种情况下，它告诉OpenGL，我们不太可能更改这些数据（它是“静态”的），并且我们将主要用它来绘制（“绘制”）。 解绑​ 还没有渲染出图吗，怎么就能解绑，一般不是要渲染结束后才操作的吗？ 在OpenGL中，解绑操作通常是为了管理状态，确保不会产生意外的副作用。下面是详细解释为何在还没有进行渲染之前就进行解绑。 预配置与实际渲染的分离： 通常，在OpenGL中的渲染过程可以分为两个主要阶段：预配置和实际渲染。 在预配置阶段，你会创建和设置各种对象（如VBO、VAO、EBO、纹理、着色器等），但并不会进行实际的绘制操作。 在实际渲染阶段，你会绑定相应的对象和调用绘制命令。 VAO的作用与设计： VAO（Vertex Array Object）被设计为捕获与顶点属性相关的所有设置和状态。一旦这些信息被储存在VAO中，你可以随时通过绑定该VAO来恢复这些状态，无需重新绑定和设置VBO、EBO等。 状态恢复与防止副作用： 当你在实际渲染阶段绑定一个VAO，OpenGL会自动恢复与该VAO相关的所有状态和设置。因此，解绑在预配置阶段并不会影响实际渲染。 解绑是一种防范措施，用于避免在后续代码中不小心修改了这些对象的状态。 代码结构与可维护性： 通过将预配置和实际渲染逻辑分开，代码更为模块化，更易于维护和调试。 这种做法也使得你可以在多个渲染调用中重用相同的预配置，而不需要每次都重新设置。 专业实践与性能优化： 在复杂的OpenGL应用中，解绑操作可能还涉及到其他考虑因素，比如多线程环境中的状态管理，或者特定硬件和驱动程序对性能的影响。 4. 创建和编译着色器你将需要一个顶点着色器来处理顶点数据，以及一个片段着色器来定义像素的颜色。 下面是顶点着色器和片段着色器的示例代码，这些代码可以直接插入你的主程序中。 1234567891011121314151617const char* vertexShaderSource = R&quot;glsl(#version 330 corelayout (location = 0) in vec3 aPos;void main(){ gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);})glsl&quot;;const char* fragmentShaderSource = R&quot;glsl(#version 330 coreout vec4 FragColor;void main(){ FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f);})glsl&quot;; 你可以使用以下代码段来编译和链接这些着色器（这一步与你提供的代码段相同）。 5. 渲染三角形在你的渲染循环中，你可以绘制三角形如下： 123456789101112131415// 清除颜色缓冲glClearColor(0.2f, 0.3f, 0.3f, 1.0f);glClear(GL_COLOR_BUFFER_BIT);// 使用着色程序glUseProgram(shaderProgram);// 绑定VAOglBindVertexArray(VAO);// 绘制三角形glDrawArrays(GL_TRIANGLES, 0, 3);// 交换缓冲区glfwSwapBuffers(window); 总结通过以上步骤，你应该能够在OpenGL窗口中绘制一个三角形。这包括定义三角形的顶点、创建和配置VBO和VAO、编写和编译着色器，以及在渲染循环中绘制三角形。这是许多更复杂的OpenGL项目的基础。 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171#include &lt;glad/glad.h&gt;#include &lt;GLFW/glfw3.h&gt;#include &lt;iostream&gt;void framebuffer_size_callback(GLFWwindow* window, int width, int height);void processInput(GLFWwindow *window);// settingsconst unsigned int SCR_WIDTH = 800;const unsigned int SCR_HEIGHT = 600;const char* vertexShaderSource = &quot;#version 330 core\\n&quot;&quot;layout (location = 0) in vec3 aPos;\\n&quot;&quot;void main()\\n&quot;&quot;{\\n&quot;&quot; gl_Position = vec4(aPos.x, aPos.y, aPos.z, 1.0);\\n&quot;&quot;}\\0&quot;;const char* fragmentShaderSource = &quot;#version 330 core\\n&quot;&quot;out vec4 FragColor;\\n&quot;&quot;void main()\\n&quot;&quot;{\\n&quot;&quot; FragColor = vec4(1.0f, 0.5f, 0.2f, 1.0f);\\n&quot;&quot;}\\n\\0&quot;;int main(){ // glfw: initialize and configure // ------------------------------ glfwInit(); glfwWindowHint(GLFW_CONTEXT_VERSION_MAJOR, 3); glfwWindowHint(GLFW_CONTEXT_VERSION_MINOR, 3); glfwWindowHint(GLFW_OPENGL_PROFILE, GLFW_OPENGL_CORE_PROFILE); // glfw window creation // -------------------- GLFWwindow* window = glfwCreateWindow(SCR_WIDTH, SCR_HEIGHT, &quot;LearnOpenGL&quot;, NULL, NULL); if (window == NULL) { std::cout &lt;&lt; &quot;Failed to create GLFW window&quot; &lt;&lt; std::endl; glfwTerminate(); return -1; } glfwMakeContextCurrent(window); glfwSetFramebufferSizeCallback(window, framebuffer_size_callback); // glad: load all OpenGL function pointers // --------------------------------------- if (!gladLoadGLLoader((GLADloadproc)glfwGetProcAddress)) { std::cout &lt;&lt; &quot;Failed to initialize GLAD&quot; &lt;&lt; std::endl; return -1; } // build and compile our shader program // ------------------------------------ // vertex shader unsigned int vertexShader = glCreateShader(GL_VERTEX_SHADER); glShaderSource(vertexShader, 1, &amp;vertexShaderSource, NULL); glCompileShader(vertexShader); // check for shader compile errors int success; char infoLog[512]; glGetShaderiv(vertexShader, GL_COMPILE_STATUS, &amp;success); if (!success) { glGetShaderInfoLog(vertexShader, 512, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::SHADER::VERTEX::COMPILATION_FAILED\\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl; } // fragment shader unsigned int fragmentShader = glCreateShader(GL_FRAGMENT_SHADER); glShaderSource(fragmentShader, 1, &amp;fragmentShaderSource, NULL); glCompileShader(fragmentShader); // check for shader compile errors glGetShaderiv(fragmentShader, GL_COMPILE_STATUS, &amp;success); if (!success) { glGetShaderInfoLog(fragmentShader, 512, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::SHADER::FRAGMENT::COMPILATION_FAILED\\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl; } // link shaders unsigned int shaderProgram = glCreateProgram(); glAttachShader(shaderProgram, vertexShader); glAttachShader(shaderProgram, fragmentShader); glLinkProgram(shaderProgram); // check for linking errors glGetProgramiv(shaderProgram, GL_LINK_STATUS, &amp;success); if (!success) { glGetProgramInfoLog(shaderProgram, 512, NULL, infoLog); std::cout &lt;&lt; &quot;ERROR::SHADER::PROGRAM::LINKING_FAILED\\n&quot; &lt;&lt; infoLog &lt;&lt; std::endl; } glDeleteShader(vertexShader); glDeleteShader(fragmentShader); // set up vertex data (and buffer(s)) and configure vertex attributes // ------------------------------------------------------------------ float vertices[] = { -0.5f, -0.5f, 0.0f, // left 0.5f, -0.5f, 0.0f, // right 0.0f, 0.5f, 0.0f // top }; unsigned int VBO, VAO; glGenVertexArrays(1, &amp;VAO); glBindVertexArray(VAO);// bind the Vertex Array Object first, then bind and set vertex buffer(s), and then configure vertex attributes(s). glGenBuffers(1, &amp;VBO); glBindBuffer(GL_ARRAY_BUFFER, VBO); glBufferData(GL_ARRAY_BUFFER, sizeof(vertices), vertices, GL_STATIC_DRAW); glVertexAttribPointer(0, 3, GL_FLOAT, GL_FALSE, 3 * sizeof(float), (void*)0); glEnableVertexAttribArray(0); glBindBuffer(GL_ARRAY_BUFFER, 0); glBindVertexArray(0); // render loop // ----------- while (!glfwWindowShouldClose(window)) { // input // ----- processInput(window); // render // ------ glClearColor(0.2f, 0.3f, 0.3f, 1.0f); glClear(GL_COLOR_BUFFER_BIT); // draw our first triangle glUseProgram(shaderProgram); glBindVertexArray(VAO); // seeing as we only have a single VAO there's no need to bind it every time, but we'll do so to keep things a bit more organized glDrawArrays(GL_TRIANGLES, 0, 3); // glBindVertexArray(0); // no need to unbind it every time // glfw: swap buffers and poll IO events (keys pressed/released, mouse moved etc.) // ------------------------------------------------------------------------------- glfwSwapBuffers(window); glfwPollEvents(); } // optional: de-allocate all resources once they've outlived their purpose: // ------------------------------------------------------------------------ glDeleteVertexArrays(1, &amp;VAO); glDeleteBuffers(1, &amp;VBO); glDeleteProgram(shaderProgram); // glfw: terminate, clearing all previously allocated GLFW resources. // ------------------------------------------------------------------ glfwTerminate(); return 0;}// process all input: query GLFW whether relevant keys are pressed/released this frame and react accordingly// ---------------------------------------------------------------------------------------------------------void processInput(GLFWwindow *window){ if (glfwGetKey(window, GLFW_KEY_ESCAPE) == GLFW_PRESS) glfwSetWindowShouldClose(window, true);}// glfw: whenever the window size changed (by OS or user resize) this callback function executes// ---------------------------------------------------------------------------------------------void framebuffer_size_callback(GLFWwindow* window, int width, int height){ // make sure the viewport matches the new window dimensions; note that width and // height will be significantly larger than specified on retina displays. glViewport(0, 0, width, height);}","link":"/2023/07/20/LeanrOpenGL1-DrawATriangle/"},{"title":"LearnOpenGL3_Camera","text":"为什么从世界坐标，转到摄像机的坐标系就能实现视图变换了视图变换的目的是将3D世界中的物体从世界坐标系转换到摄像机坐标系。这个转换为何能实现视图变换，我们可以从以下几个方面来理解： 1. 摄像机的位置和方向在世界坐标系中，摄像机可以位于任何位置，并朝任何方向。但在摄像机坐标系中，摄像机始终位于原点，并朝向-z轴。通过将物体从世界坐标系转换到摄像机坐标系，我们实际上是在将整个场景移动和旋转，使摄像机的位置和方向与新坐标系的原点和方向对齐。 2. 视点的模拟当物体被转换到摄像机坐标系中时，它们的位置和方向是相对于摄像机的。这意味着我们现在看到的物体是从摄像机的视点观察的。这就是为什么这个变换被称为“视图”变换的原因：它模拟了从摄像机的视点查看场景的效果。 3. 后续的投影视图变换后，物体位于摄像机坐标系中，我们可以进一步应用投影变换。投影变换将3D摄像机坐标系中的物体投影到2D平面上，模拟了摄像机镜头的效果。这一步是在视图变换的基础上进行的，因为投影必须考虑摄像机的位置和方向。 总结视图变换通过将物体从世界坐标系转换到摄像机坐标系，实现了场景的移动和旋转，使摄像机的位置和方向与新坐标系的原点和方向对齐。这个转换模拟了从摄像机的视点观察场景的效果，并为后续的投影变换提供了基础。 通过将物体转换到与摄像机视角相对应的坐标系，我们可以实现3D场景的逼真渲染，使观察者感觉自己就在场景中，可以自由移动和观察。这是3D图形渲染中的基本概念，用于创建沉浸式和逼真的虚拟世界。 构建摄像机/观察空间 观察空间是一个坐标系统，其中摄像机位于原点，摄像机的方向定义了新坐标系统的轴。 以下是创建观察空间的步骤概述： 摄像机位置：定义摄像机在世界空间中的位置。 摄像机方向：计算摄像机的方向向量，通常是通过摄像机位置和目标位置的差来计算。 右轴：通过摄像机方向向量和一个初始的上向量的叉乘来计算右向量，代表摄像机空间的x轴的正方向。 上轴：通过右向量和方向向量的叉乘来计算上向量，代表摄像机空间的y轴的正方向。 这些向量共同定义了观察空间，可以用于构建LookAt矩阵，该矩阵将世界坐标转换为相对于摄像机位置和方向的观察坐标。这是3D图形中常用的技术，允许我们从摄像机的视角查看场景，就像我们在现实世界中看到的一样。 通过使用LookAt矩阵，你可以实现各种摄像机效果，如第一人称摄像机、第三人称摄像机等，从而增强3D应用程序的真实感和沉浸感。 1、摄像机位置：定义摄像机在世界空间中的位置。是我们自己构建的是吗？ 是的，定义摄像机在世界空间中的位置是你自己构建的一部分。摄像机的位置是一个3D向量，表示摄像机在世界坐标系中的位置。你可以根据需要自由选择这个位置。 例如，你可以将摄像机放置在世界空间的原点上，或者将其放置在场景的任何其他位置。摄像机的位置将决定你从哪个角度观察场景。 在OpenGL和GLM库中，你可以这样定义摄像机的位置： 1glm::vec3 cameraPos = glm::vec3(0.0f, 0.0f, 3.0f); 这里，摄像机位于世界空间的(0.0, 0.0, 3.0)位置。你可以根据场景的具体需求调整这些值。 摄像机的位置是3D图形中许多计算的基础，例如计算摄像机的方向、构建观察矩阵等。因此，正确设置摄像机的位置对于创建逼真的3D视觉效果至关重要。 2、初始向量上向量为什么不能直接作为上轴右轴：通过摄像机方向向量和一个初始的上向量的叉乘来计算右向量，代表摄像机空间的x轴的正方向。在这一句中，这个初始的上向量，不就是4的上轴了吗 你的观察是正确的，但让我详细解释一下这个过程。 在计算右轴时，我们确实使用了一个初始的上向量，但这个初始的上向量并不是最终的摄像机上轴。这个初始的上向量通常是一个全局的上向量，例如(0.0f, 1.0f, 0.0f)，代表世界空间中的y轴正方向。 以下是计算过程的步骤： 选择初始上向量：选择一个全局的上向量，例如(0.0f, 1.0f, 0.0f)。 计算右轴：使用初始上向量和摄像机方向向量的叉乘来计算右向量。这个右向量代表摄像机空间的x轴正方向。 计算真实的上轴：使用右向量和摄像机方向向量的叉乘来计算真实的上向量。这个上向量代表摄像机空间的y轴正方向。 代码示例： 123glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f); // 初始上向量glm::vec3 cameraRight = glm::normalize(glm::cross(up, cameraDirection)); // 右轴glm::vec3 cameraUp = glm::cross(cameraDirection, cameraRight); // 真实的上轴 这个过程确保了右轴、上轴和摄像机方向向量彼此正交，并且符合右手坐标系。这是构建观察空间所必需的。 反例：当然，让我们通过一个更通用的例子来说明为什么不能直接使用初始的上向量作为摄像机的上轴。 假设摄像机方向向量指向一个斜下方的点，例如： 1glm::vec3 cameraDirection = glm::normalize(glm::vec3(1.0f, -1.0f, -1.0f)); 现在，我们选择世界空间中的标准上向量作为初始的上向量： 1glm::vec3 up = glm::vec3(0.0f, 1.0f, 0.0f); 如果我们直接使用这个初始的上向量作为摄像机的上轴，那么摄像机的上方向将与世界空间的y轴正方向对齐。然而，由于摄像机是朝着斜下方看的，所以摄像机的真实上方向实际上是稍微倾斜的。 现在，让我们按照之前描述的方法计算右轴和真实的上轴： 12glm::vec3 cameraRight = glm::normalize(glm::cross(up, cameraDirection));glm::vec3 cameraUp = glm::cross(cameraDirection, cameraRight); 通过这种方法计算得到的真实上轴将与摄像机的方向和右轴垂直，反映了摄像机的真实上方向。 如果我们直接使用初始的上向量作为摄像机的上轴，那么得到的三个轴可能不会彼此垂直，从而破坏了观察空间的完整性。通过使用摄像机方向向量和右轴的叉乘来计算真实的上轴，我们可以确保得到的三个轴彼此垂直，并且与摄像机的实际方向和方位对齐。 这个例子说明了为什么我们不能直接使用初始的上向量作为摄像机的上轴，而是需要通过计算来得到真实的上轴。这确保了观察空间的完整性和准确性。 3、那上向量不是能算是真实的上轴，为什么它可以用来计算右轴你提出了一个很好的问题，让我们深入探讨一下。 当我们计算右轴时，我们使用初始上向量和摄像机方向向量的叉乘。这个初始上向量通常是世界空间中的y轴正方向，例如(0.0f, 1.0f, 0.0f)。我们选择这个向量是因为它是一个方便的、已知的方向，通常与大多数摄像机方向不平行。 现在，为什么我们可以使用这个初始上向量来计算右轴，即使它不是摄像机的真实上轴？ 叉乘的性质：叉乘的结果是一个向量，该向量垂直于参与叉乘的两个向量。因此，使用摄像机方向向量和初始上向量的叉乘来计算右轴可以确保得到的右轴与摄像机方向向量垂直。 选择合适的初始上向量：我们选择的初始上向量通常与摄像机方向向量不平行（除非摄像机完全朝上或朝下）。这确保了叉乘的结果不是零向量，并且定义了摄像机空间的x轴正方向。 真实上轴的计算：一旦我们有了右轴，我们可以使用摄像机方向向量和右轴的叉乘来计算真实的上轴。这个真实的上轴与摄像机方向向量和右轴都垂直，因此它反映了摄像机的真实上方向。 总的来说，我们使用初始上向量来计算右轴，因为它是一个方便的、已知的方向，可以确保得到的右轴与摄像机方向向量垂直。然后，我们使用右轴和摄像机方向向量的叉乘来计算真实的上轴，确保所有三个轴彼此垂直，并且与摄像机的实际方向和方位对齐。这个过程确保了观察空间的完整性和准确性。","link":"/2023/08/12/LearnOpenGL3-Camera/"},{"title":"InvertedHullOutlines","text":"原理“Inverted Hull”（反向包围壳）方法的实现原理如下： 在模型的边缘产生轮廓线效果。首先，这个方法创建了一个与原始模型相同的包围壳（hull），但是将其沿着模型的法线方向向外扩展。具体来说，在顶点着色器中，每个顶点的位置被加上沿法线方向扩展的距离，这个距离由轮廓线的厚度参数控制。 在渲染过程中，背面剔除（Cull Front）被应用于扩展后的包围壳。这意味着，只有扩展包围壳的背面（朝向摄像机的一面）会被渲染。原始模型的前面将不受影响。 在渲染扩展包围壳时，片段着色器会使用指定的轮廓线颜色填充背面。这样，在原始模型边缘的地方，轮廓线将被绘制出来。 由于原始模型和扩展包围壳的深度值相近，轮廓线会被绘制在原始模型的边缘，从而实现轮廓线效果。 这种方法通常在许多情况下可以实现轮廓线效果，但在复杂的几何形状、模型法线不一致或遮挡关系较复杂的情况下可能出现不理想的效果。当模型的内部部分被扩展包围壳的背面所遮挡时，可能会在非边缘部分产生轮廓线。 缺点在这个轮廓线Shader中，轮廓线的效果是通过将模型的法线向外推移，然后绘制该模型的背面（Cull Front），从而在原始模型的边缘显示出轮廓线。在大多数情况下，这种方法可以产生较好的效果。然而，在某些情况下，这种方法可能会导致在非边缘部分产生轮廓线。原因有以下几点： 几何形状的复杂性：对于复杂的几何形状，尤其是那些具有很多相互靠近的部分的形状，可能会出现非边缘部分的轮廓线。因为在将顶点沿法线方向推移时，相邻的顶点可能会相互穿越，导致轮廓线在错误的位置出现。 法线方向的不一致：如果模型的法线方向不一致，可能会导致非边缘部分出现轮廓线。例如，如果模型的一部分法线朝向模型内部，而另一部分法线朝向模型外部，当将顶点沿法线方向推移时，可能会导致非边缘部分出现轮廓线。 为了解决这个问题，可以尝试以下方法： 优化模型：优化模型的几何形状，确保相互靠近的部分有足够的间隔，以避免轮廓线在非边缘部分出现。 检查并修复法线：检查模型的法线方向，确保它们是一致的。如果发现问题，可以使用3D建模软件修复法线。 使用不同的轮廓线绘制方法：如果问题仍然存在，可以尝试使用不同的轮廓线绘制方法。例如，您可以使用基于屏幕空间的轮廓线着色器，它是通过计算屏幕空间中的深度差异来绘制轮廓线，这种方法通常能够更准确地在边缘部分绘制轮廓线。然而，这种方法的性能开销可能会更高，因为它需要在屏幕空间进行计算。 代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107Shader &quot;Tutorial/020_InvertedHull/Surface&quot; { Properties { _Color (&quot;Tint&quot;, Color) = (0, 0, 0, 1) _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; {} _Smoothness (&quot;Smoothness&quot;, Range(0, 1)) = 0 _Metallic (&quot;Metalness&quot;, Range(0, 1)) = 0 [HDR] _Emission (&quot;Emission&quot;, color) = (0,0,0) _OutlineColor (&quot;Outline Color&quot;, Color) = (0, 0, 0, 1) _OutlineThickness (&quot;Outline Thickness&quot;, Range(0,1)) = 0.1 _OutlineMinThickness (&quot;Outline Min Thickness&quot;, Range(0,1)) = 0.001 _OutlineMaxThickness (&quot;Outline Max Thickness&quot;, Range(0,1)) = 0.1 } SubShader { //the material is completely non-transparent and is rendered at the same time as the other opaque geometry Tags{ &quot;RenderType&quot;=&quot;Opaque&quot; &quot;Queue&quot;=&quot;Geometry&quot;} CGPROGRAM #pragma surface surf Standard fullforwardshadows #pragma target 3.0 sampler2D _MainTex; fixed4 _Color; half _Smoothness; half _Metallic; half3 _Emission; //input struct which is automatically filled by unity struct Input { float2 uv_MainTex; }; //the surface shader function which sets parameters the lighting function then uses void surf (Input i, inout SurfaceOutputStandard o) { //read albedo color from texture and apply tint fixed4 col = tex2D(_MainTex, i.uv_MainTex); col *= _Color; o.Albedo = col.rgb; //just apply the values for metalness, smoothness and emission o.Metallic = _Metallic; o.Smoothness = _Smoothness; o.Emission = _Emission; } ENDCG //The second pass where we render the outlines Pass{ Cull Front CGPROGRAM //include useful shader functions #include &quot;UnityCG.cginc&quot; //define vertex and fragment shader #pragma vertex vert #pragma fragment frag //tint of the texture fixed4 _OutlineColor; float _OutlineThickness; float _OutlineMinThickness; float _OutlineMaxThickness; //the object data that's put into the vertex shader struct appdata{ float4 vertex : POSITION; float4 normal : NORMAL; }; //the data that's used to generate fragments and can be read by the fragment shader struct v2f{ float4 position : SV_POSITION; }; //the vertex shader v2f vert(appdata v){ v2f o; float3 objectScale = float3( length(unity_ObjectToWorld._11_21_31), length(unity_ObjectToWorld._12_22_32), length(unity_ObjectToWorld._13_23_33) ); float thickness = lerp(_OutlineMinThickness, _OutlineMaxThickness, _OutlineThickness); float objectSize = length(objectScale) / 3.0; float relativeThickness = thickness * objectSize; // o.position = UnityObjectToClipPos(v.vertex + normalize(v.normal) * _OutlineThickness); o.position = UnityObjectToClipPos(v.vertex + normalize(v.normal) * relativeThickness); return o; } //the fragment shader fixed4 frag(v2f i) : SV_TARGET{ return _OutlineColor; } ENDCG } } FallBack &quot;Standard&quot;} 为什么一定要通过法线外移：123o.position = UnityObjectToClipPos(v.vertex + normalize(v.normal) * _OutlineThickness);//为什么要通过法线外移，不能直接改成： o.position = UnityObjectToClipPos(v.vertex + _OutlineThickness); 使用法线方向来外移顶点是为了确保轮廓线沿着模型的表面扩展。法线表示了模型表面的方向，因此沿着法线移动顶点可以使轮廓线紧贴模型表面。如果直接使用o.position = UnityObjectToClipPos(v.vertex + _OutlineThickness);，这将不会考虑模型的表面方向，而是在模型的每个顶点上添加一个固定的偏移量。 这种方法可能导致轮廓线不再紧贴模型表面，而是在空间中随意偏移。在某些情况下，这可能导致轮廓线出现不正确或不自然的效果。因此，使用法线方向来外移顶点是创建轮廓线效果的更合适方法。","link":"/2023/05/07/InvertedHullOutlines/"},{"title":"LearnOpenGL4-Colors","text":"颜色相乘原理当光线照射到物体上时，物体的颜色由它对不同颜色分量的光反射和吸收决定。在计算物体的最终颜色时，通常使用光源的颜色和物体的颜色相乘来模拟这一过程。 具体来说： 光源的颜色（例如，光源的发出的光）通常以RGB（红、绿、蓝）格式表示。 物体的颜色也以RGB格式表示。 当光线照射到物体上时，物体会根据其颜色属性对光线的不同分量进行吸收。吸收的颜色分量将不再可见，而被吸收的能量将被转化为热量。 剩下的未被吸收的光线分量被物体反射回来，成为我们所观察到的颜色。这个反射的颜色也以RGB格式表示。 最终，我们看到的物体颜色是光源颜色和物体颜色之间的乘积。这意味着如果物体吸收了某种颜色分量，那么这种颜色分量将不会出现在最终的物体颜色中。 这个过程可以通过将光源颜色与物体颜色相乘来模拟。例如，如果光源是红色(1, 0, 0)，物体是绿色(0, 1, 0)，那么乘积(1, 0, 0) * (0, 1, 0) = (0, 0, 0)，这意味着物体会吸收光源的红色分量，最终呈现为黑色。 这就是为什么在计算光照和渲染物体颜色时，通常使用这种基本的颜色相乘原理 例子：123glm::vec3 lightColor(0.0f, 1.0f, 0.0f);glm::vec3 toyColor(1.0f, 0.5f, 0.31f);glm::vec3 result = lightColor * toyColor; // = (0.0f, 0.5f, 0.0f); 这个玩具吸收了光线中一半的绿色值，但仍然也反射了一半的绿色值。玩具现在看上去是深绿色(Dark-greenish)的。我们可以看到，如果我们用绿色光源来照射玩具，那么只有绿色分量能被反射和感知到，红色和蓝色都不能被我们所感知到。","link":"/2023/09/06/LearnOpenGL4-Colors/"},{"title":"LearnOpenGL5-BasicLighting","text":"环境光 (Ambient Lighting) 环境光是光照模型中的一个组件，其目的是模拟现实世界中无处不在的背景光。在现实生活中，光不仅仅是直接从光源射出并照亮物体，而且还会从物体反射、散射到其他物体上，这使得即使在没有直接光线照射的地方，物体仍然可以看到一些光线。 例如，想象一个房间只有一个窗户，窗户的外面是太阳光。虽然太阳光只直接照亮房间的部分区域，但房间的其他部分并不是完全黑暗的，因为光线从地板、墙壁和其他物体上反射并散射到了那些没有直接受到太阳光照射的区域。这种间接的、全方位的光照就是环境光的现实基础。 在计算机图形学的基础光照模型中，真正模拟所有这些间接的光线反射和散射是非常复杂的，特别是在需要实时渲染的应用中。为了简化这一问题，环境光被引入作为一个简化的模型，为场景中的所有物体提供一个常数的亮度，以模拟这种无处不在的背景光。 在实际的编程实现中，环境光通常通过以下方式来计算： Iambient = Ilight X Kambient Iambient 是最终的环境光亮度 Ilight 是光源的环境光强度。 Kambient是物体的环境光反射系数，通常为一个介于0和1之间的值，表示物体如何反射环境光。 这种方法的一个主要缺点是它不考虑场景中的物体对环境光的遮挡。这就是为什么更高级的光照方法，如全局照明，尝试模拟这些遮挡效应，以获得更真实的渲染结果。 延伸模拟环境光的遮挡效应通常需要更复杂的光照技术。其中一些主要的方法和技术如下： 全局照明 (Global Illumination): 这是一组算法和技术，旨在模拟光如何在场景中的物体之间反弹。其中最著名的全局照明算法有 Radiosity 和光线追踪 (Ray Tracing)。 环境光遮挡 (Ambient Occlusion, AO): AO 是一种技术，用于模拟小范围内的环境光遮挡。基本思想是检查物体表面的每个点周围的其他物体，以确定这个点有多少光被阻挡。结果是，凹陷或接近其他物体的地方通常会更暗，因为它们受到更多的遮挡。 屏幕空间环境光遮挡 (Screen Space Ambient Occlusion, SSAO): 这是一种实时渲染中常用的技术，它在屏幕空间内模拟AO，通常比传统的AO方法更快。 Photon Mapping: 这是一种模拟光如何在场景中反弹的方法。它通过追踪光子（光的粒子）来工作，这些光子从光源发射并在与物体相交时存储信息。 Path Tracing: 这是一种基于光线追踪的技术，它模拟光线如何从相机发射并在场景中多次反弹。每次反弹都会收集光照信息，从而模拟间接照明效果。 当考虑实时应用（如视频游戏）时，性能是一个重要的问题。因此，常常会使用近似和优化技术来实现上述方法。对于不需要实时的应用，例如电影制作或静态渲染，可以使用更精确（但计算密集型）的方法来获得最佳的光照效果。 总的来说，模拟环境光的遮挡和反弹是一个复杂的任务，需要权衡计算复杂性、实时性和渲染质量。 漫反射 (Diffuse Lighting) - 漫反射是当光线击中物体表面后，光线会均匀地、各向异性地散射。这意味着光线不会像在镜面反射中那样只沿一个方向反射，而是会在许多方向上散射。这是大多数物体（特别是那些没有光泽的物体）显示其固有颜色的主要方式。 漫反射的计算 漫反射计算公式。 [ I_{diffuse} = I_{light} \\times K_{diffuse} \\times max(0, \\vec{N} \\cdot \\vec{L}) ] 这个公式描述了在一个特定点上漫反射的亮度是如何被计算的。 ( I_{light} ) 这是光源的亮度。这可以是一个RGB颜色值，其中R、G、B分别代表红、绿、蓝的亮度。一个光源的亮度可以是常数，例如一个常亮的点光源，或者它可以基于距离、方向或其他因素而变化。 ( K_{diffuse} ) 这是物体的漫反射材质系数。它也是一个RGB颜色值，表示物体的固有颜色。例如，红色的苹果可能有一个高的红色分量和较低的绿色和蓝色分量。 ( \\vec{N} ) 和 ( \\vec{L} ) ( \\vec{N} ) 是物体表面上点的法线向量。法线是垂直于表面的一个单位向量。 ( \\vec{L} ) 是从物体表面上的点指向光源的向量。 这两个向量的点积 ( \\vec{N} \\cdot \\vec{L} ) 会得到一个标量值，这个值表示两个向量之间的角度的余弦值。 当光完全垂直照在物体表面上时（即法线向量与指向光源的向量之间的角度为0度），点积的值为1，表示光的强度是最大的。当光与物体表面形成一个锐角时，点积的值逐渐减小，表示光的强度减弱。当光线与物体表面平行时，点积的值为0，表示没有光照亮该表面。 max(0, \\vec{N} \\cdot \\vec{L}) 使用max函数确保当光线在物体表面的背面（即点积为负数）时，漫反射亮度为0。这是因为，从几何上看，如果光线在物体的背面，那么这个点就不应该受到光源的照射。 整个公式的结果 ( I_{diffuse} ) 是一个RGB颜色值，表示由于漫反射而在物体表面上产生的亮度。通过将这个值与场景中其他的光照效果（如环境光和镜面反射）结合起来，我们可以得到物体在特定点上的总亮度。 关于法线法线（normal）这个概念并不是专门为了漫反射而创建的。法线在数学和计算机图形学中是一个基础概念，用于描述一个表面上某一点的方向。这个方向垂直于该点处的表面。 法线在很多计算机图形学的应用中都是非常关键的，其中包括： 光照计算：如我们之前讨论的，法线用于计算一个表面点如何与光互动，不仅限于漫反射，还包括环境光、镜面反射等。 碰撞检测：在物理模拟和游戏中，法线可以用于确定物体在碰撞后应该如何反弹。 纹理映射：在高级的渲染技术中，如法线映射（normal mapping），法线用于模拟表面的细节，使其看起来更加真实，即使在没有实际几何细节的情况下。 曲面细分：在曲面建模和细分中，法线用于帮助决定如何拆分或细分一个表面，以得到更平滑或更精细的结果。 总之，法线是计算机图形学中的一个核心概念，它在很多方面都有应用，而不仅仅是在漫反射光照中。","link":"/2023/10/12/LearnOpenGL5-BasicLighting/"},{"title":"PolarCoordinates","text":"什么是极坐标极坐标（Polar coordinates）是一种描述平面上点位置的坐标系统。在极坐标系统中，一个点的位置由它与原点的距离和它与参考方向（通常是正向 x 轴）的夹角来表示。 极坐标系统的坐标表示通常以 (r, θ) 的形式，其中 r 是点到原点的距离（极径），θ 是点与参考方向的夹角（极角）。极径 r 通常是非负数，而极角 θ 则通常用弧度表示，可以是任意实数。 相比之下，笛卡尔坐标系统使用直角坐标表示点的位置，即以水平和垂直的坐标轴（通常是 x 轴和 y 轴）的数值来表示点的位置。 极坐标系统在某些情况下可以更方便地描述点的位置和进行某些操作。例如，极坐标可以更直观地表示圆形、环形、螺旋等几何形状，以及进行旋转、缩放和扭曲等变换操作。在图形学、物理学、工程学等领域，极坐标系统常被用于描述和处理与圆形、圆环、径向对称等相关的问题。 极坐标的转换123456789#ifndef POLAR_COORDINATES#define POLAR_COORDINATESfloat2 toPolar(float2 cartesian){ float distance = length(cartesian); float angle = atan2(cartesian.y, cartesian.x); return float2(angle / UNITY_TWO_PI, distance);}#endif 角度除以2π。这个除法的目的是将角度值归一化，并使其范围从-0.5到0.5，而不是常见的-π到π范围。这种归一化可以使角度在处理中更加方便，特别是在着色器编程或其他常用归一化值的应用中，如纹理坐标的映射等。相比之下，原始的角度范围(-π到π)可能更难以处理和控制。 如果直接根据以上的公式转换uv，会得出以下的渲染效果 123456//the fragment shader functionfixed4 frag (v2f i) : SV_Target { //get polar coordinates float2 uv = toPolar(i.uv); return float4(frac(uv), 0, 1); //test output} 在这里，只能看到1/4的圆。这是因为，正如前面所描述的，是围绕着“中心”计算角度，而在这里中心位于右下角。幸运的是，在笛卡尔空间中移动中心点非常容易，只需在转换之前从每个轴上减去0.5。由于HLSL会自动将标量转换为每个值都设置为该标量的向量，可以直接写作uv - 0.5。这样，空间范围将变为-0.5到0.5，因此让我其乘以2，以便得到-1到1的范围，并完整显示0-1空间。 123456789//the fragment shader functionfixed4 frag (v2f i) : SV_Target { //make input uvs centered and scaled to -1 to 1 i.uv -= 0.5; i.uv *= 2; //get polar coordinates float2 uv = toPolar(i.uv); return float4(frac(uv), 0, 1); //test output} 12345678910111213141516//the fragment shader functionfixed4 frag (v2f i) : SV_Target { //make input uvs centered and scaled to -1 to 1 i.uv -= 0.5; i.uv *= 2; //get polar coordinates float2 uv = toPolar(i.uv); //move discontinuity in coordinates to 0 uv.x = frac(uv.x); //tile Image // uv.x *= 3; // sample the texture and apply tint fixed4 col = tex2D(_MainTex, uv) * _Color; //return the final color to be drawn on screen return col;} 对于整个图像来说，完全的旋转可能会过于夸张并且会导致图像被拉伸,通过将其平铺多次以获得更好的结果，通过将uv.x乘以3，使图像在x轴上重复3次。这样做可以使得图像的纹理在坐标范围内重复出现，从而创建出更丰富的视觉效果。 1uv.x *= 3; 当在极坐标转换后的纹理坐标中，角度值跳跃从-1.5到1.5的时候，会出现奇怪的无缝问题。这是因为在这些像素点上，纹理采样时会根据内部的局部导数判断我们是否在很远的地方查看纹理，并选择较低的mipmap级别。解决这个问题的”正确”方法是自己计算mipmap级别，然后将其传递给tex2Dlod函数,原文提供了另一篇优秀文章的链接，介绍了这个问题的解决方法：https://bgolus.medium.com/distinctive-derivative-differences-cce38d36797b。 另一种解决方法是将这个无缝问题移动到不太明显的地方。在这种情况下，可以只取输出的x坐标的小数部分，因为默认情况下它的范围是-0.5到0.5，经过处理后会变成0到1，而无缝问题就位于第一张图像的起始处，即0度位置。通过这种处理方式，可以将无缝问题的边缘移动到不太明显的位置，从而减少其对图像的影响。 1uv.x = frac(uv.x); 文章参考于：https://www.ronja-tutorials.com/post/053-polar-coordinates/","link":"/2023/06/23/PolarCoordinates/"},{"title":"SpriteOutline","text":"​ 由于项目需求，需要实现一个同一预制体下所有子物体精灵组合外描边的功能 ，如下图的效果： 本来以为是很简单的一个需求，这个网络上应该有很多成熟的方案。然后开始了两周的不断试错及踩坑功能。 方案一踩坑：首先找到的是资源商店里面的这个资源： https://assetstore.unity.com/packages/vfx/shaders/photoshop-like-2d-sprite-outline-stroke-effect-105207?locale=zh-CN 这个方案的原理也很简单，就是遍历子所有子物体，读取象素信息，然后共同按照计算好的区域写入到一个Texture中，最后把Texture赋值给sprite。 这里由此产生了几个问题： 问题1：由于是新new写入的Texture，在项目中会打断图集，DC会成倍产生 问题2：在测试性能中发现场景中的物体超过50个(每个下有三个SpriteRender子物体)电脑上的运行时间直接超过了1s,在查了Profiler后发现是下面这个循环代码很慢。 12345678for (int y = 0; y &lt; height; y++) { for (int x = 0; x &lt; width; x++) { int index = width * y + x; if (pixels [index].a &gt; 0) { texture.SetPixel (x+(int)vo.offset.x , y+(int)vo.offset.y, pixels [index]); } }} 主要是这句 1texture.SetPixel (x+(int)vo.offset.x , y+(int)vo.offset.y, pixels [index]); 查了网上相关资源，建议不要在for里面使用SetPixel方法，建议使用SetPixels32或GetRawTextureData(https://docs.unity3d.com/ScriptReference/Texture2D.GetRawTextureData.html)替代,尝试使用SetPixels32，第一个Sprite的像素信息写入是正常的，但后面写入的像素信息都不正常，想不到相关处理方案优化陷入僵局。 问题3：这个方案处理出来的边沿锯齿问题还是严重，不够平滑，锯齿表现严重，研究了抗锯齿的方案，未能很好的处理这个问题（这个挖个坑，以后研究一下）放大如下图： 对Shader不是很熟悉，也研究了许久也算是一种思路启发，现在贴上： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153// Unity built-in shader source. Copyright (c) 2016 Unity Technologies. MIT license (see license.txt)Shader &quot;Sprites/_OutlinePro&quot;{ Properties { _Size (&quot;Size&quot;, Int) = 1 _BlurSize (&quot;Blur Size&quot;, Int) = 0 _Color (&quot;Color&quot;, Color) = (1,1,1,1) _BlurAlphaMultiplier (&quot;Blur Alpha Multiplier&quot;, Float) = 0.7 _BlurAlphaChoke (&quot;Blur Alpha Choke&quot;, Float) = 1 _AlphaThreshold (&quot;Alpha Threshold&quot;, Float) = 0.05 _Buffer (&quot;Buffer&quot;, Int) = 0 [PerRendererData] _MainTex (&quot;Sprite Texture&quot;, 2D) = &quot;white&quot; {} //[HideInInspector] _Color (&quot;Tint&quot;, Color) = (1,1,1,1) //[MaterialToggle] PixelSnap (&quot;Pixel snap&quot;, Float) = 0 //[HideInInspector] _RendererColor (&quot;RendererColor&quot;, Color) = (1,1,1,1) [HideInInspector] _Flip (&quot;Flip&quot;, Vector) = (1,1,1,1) //[PerRendererData] _AlphaTex (&quot;External Alpha&quot;, 2D) = &quot;white&quot; {} //[PerRendererData] _EnableExternalAlpha (&quot;Enable External Alpha&quot;, Float) = 0 } SubShader { Tags { &quot;Queue&quot; = &quot;Transparent&quot; &quot;IgnoreProjector&quot; = &quot;True&quot; &quot;RenderType&quot; = &quot;Transparent&quot; &quot;PreviewType&quot; = &quot;Plane&quot; &quot;CanUseSpriteAtlas&quot; = &quot;True&quot; } Cull Off Lighting Off ZWrite Off Blend One OneMinusSrcAlpha Pass { CGPROGRAM #pragma vertex SpriteVert #pragma fragment OutlineSpriteFrag //#pragma target 4.0 #pragma multi_compile_instancing //#pragma multi_compile _ PIXELSNAP_ON //#pragma multi_compile _ ETC1_EXTERNAL_ALPHA #include &quot;UnitySprites.cginc&quot; float4 _MainTex_TexelSize; int _Size; int _BlurSize; //float4 _Color; float _BlurAlphaMultiplier; float _BlurAlphaChoke; float _AlphaThreshold; int _Buffer; float2 _inTexcoord; float4 _pixelTexcoord; float _pixelAlpha; int _blurThickness; int _strokeThickness; fixed4 _clearColor; fixed4 _outColor; float Distance(int x1, int y1, int x2, int y2) { int deltaX = x2-x1; int deltaY = y2-x1; int valTemp = deltaX * deltaX + deltaY * deltaY; return rsqrt(valTemp)*valTemp; } float InverseLerp(float a, float b, float value) { return clamp ((value - a) / (b - a), 0, 1); } //是否存在此象素 bool HasPixelAt(int x, int y) { _pixelTexcoord.x = _inTexcoord.x + (x * _MainTex_TexelSize.x); _pixelTexcoord.y = _inTexcoord.y + (y * _MainTex_TexelSize.y); _pixelAlpha = tex2Dlod (_MainTex, _pixelTexcoord).a; return (_pixelAlpha &gt;= _AlphaThreshold); } //这里主要是差值当前像素的透明度，和颜色设置 bool TrySetPixelAt(int x, int y) { if (!HasPixelAt (x, y)) return false; //获得当前透明象素到最近的不透明象素的距离 float pixelDistance = Distance (0, 0, x, y); pixelDistance -= _Buffer; if (pixelDistance &lt;= 0 || pixelDistance &gt; _Size) return true; //当前像素在所在_strokeThickness, _Size间的位置 float distancePercent = InverseLerp (_strokeThickness, _Size, pixelDistance); //distancePercent = lerp (distancePercent, 1 - distancePercent, _InvertBlur); //chokeScalar = lerp (chokeScalar, distancePercent, _InvertBlur); float blurAlphaMultiplier = lerp (_BlurAlphaMultiplier, _BlurAlphaMultiplier / _Size, distancePercent); float blurAlphaChoke = max (0.95, (pixelDistance - _strokeThickness) * _BlurAlphaChoke ) /0.95; float alphaScalar = ceil (saturate (pixelDistance - _strokeThickness)); // Only blur pixels greater than the stroke thickness. float finalColor = _Color.a * blurAlphaMultiplier / blurAlphaChoke; //更新透明度 _outColor.a = lerp (_Color.a,finalColor, alphaScalar); _outColor.rgb = _Color.rgb * _outColor.a; return true; } fixed4 OutlineSpriteFrag(v2f IN) : SV_Target { _inTexcoord = IN.texcoord; //模糊的厚度 _blurThickness = min (_BlurSize, _Size - 1); //线条厚度 _strokeThickness = _Size - _blurThickness; //maxGridRadius = _Size + _Buffer 线条至模糊范围 int i, j, gridSize, dir = -1, maxGridRadius = _Size + _Buffer; for (int gridRadius = 1; gridRadius &lt;= maxGridRadius; gridRadius++) { gridSize = gridRadius*2; j= 0; for (i = 0; i &lt; gridSize; i++) { j += i * dir; dir *= -1; //return false为重叠部分，不填充颜色直接返回颜色，不进入计算 if (TrySetPixelAt (0, 0)) return _clearColor; //对四个方向都做出差值 if (TrySetPixelAt (-gridRadius, j) || TrySetPixelAt (j, gridRadius) || TrySetPixelAt (gridRadius, -j) || TrySetPixelAt (-j, -gridRadius)) return _outColor; } } return _outColor; } ENDCG } }} 方案一总结：由于要使用GetPixels读取像素信息重新生成一个Texture并重新写入，GetPixels过程中会从GPU重新复制一个Texture到CPU中，在内存中会有两份数据同时存在，这个方案合适于当前要显示的数量不多的请况下 更改思路：根据方案一的总结，重新思考了解决方向，舍弃把所有像素写在一张贴图上的想法，直接备份两分，一份不描边，一份描边，描边的放在后面。 由于只用考虑描边功能，感觉应该是挺好实现的。于是有了以下 方案二：在翻github，找到这么一个方案，就是上下左右四个方向，用四个pass分别做偏移最后做一个混合，先贴上代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214// Upgrade NOTE: replaced 'mul(UNITY_MATRIX_MVP,*)' with 'UnityObjectToClipPos(*)'Shader &quot;Sprites/Outline&quot;{ Properties { [PerRendererData] _MainTex (&quot;Sprite Texture&quot;, 2D) = &quot;white&quot; {} _Color (&quot;Tint&quot;, Color) = (1,1,1,1) [MaterialToggle] PixelSnap (&quot;Pixel snap&quot;, Float) = 0 // Add values to determine if outlining is enabled and outline color. [PerRendererData] _OutlineSize (&quot;Outline&quot;, Float) = 0 [PerRendererData] _OutlineColor(&quot;Outline Color&quot;, Color) = (1,1,1,1) } CGINCLUDE #include &quot;UnityCG.cginc&quot; struct appdata_t { float4 vertex : POSITION; float4 color : COLOR; float2 texcoord : TEXCOORD0; }; struct v2f { float4 vertex : SV_POSITION; fixed4 color : COLOR; float2 texcoord : TEXCOORD0; }; fixed4 _Color; v2f vert_outline(appdata_t IN) { v2f OUT; OUT.vertex = UnityObjectToClipPos(IN.vertex); OUT.texcoord = IN.texcoord; OUT.color = IN.color * _Color; #ifdef PIXELSNAP_ON OUT.vertex = UnityPixelSnap (OUT.vertex); #endif return OUT; } sampler2D _MainTex; sampler2D _AlphaTex; float4 _MainTex_TexelSize; //magic var float _OutlineSize; //outline size fixed4 _OutlineColor; // outlie color fixed4 SampleSpriteTexture (float2 uv) { fixed4 color = tex2D (_MainTex, uv); return color; } ENDCG SubShader { Tags { &quot;Queue&quot;=&quot;Transparent&quot; &quot;IgnoreProjector&quot;=&quot;True&quot; &quot;RenderType&quot;=&quot;Transparent&quot; &quot;PreviewType&quot;=&quot;Plane&quot; &quot;CanUseSpriteAtlas&quot;=&quot;True&quot; } Cull Off Lighting Off ZWrite Off Blend One OneMinusSrcAlpha //outline down Pass { Offset 1, 1 CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma shader_feature ETC1_EXTERNAL_ALPHA v2f vert(appdata_t IN) { return vert_outline(IN); } fixed4 frag(v2f IN) : SV_Target { fixed4 texColor = SampleSpriteTexture (IN.texcoord + fixed2(0,_MainTex_TexelSize.y*_OutlineSize)) * IN.color; fixed4 c = _OutlineColor * texColor.a; return c; } ENDCG } //outline up Pass { Offset 1, 1 CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma shader_feature ETC1_EXTERNAL_ALPHA v2f vert(appdata_t IN) { return vert_outline(IN); } fixed4 frag(v2f IN) : SV_Target { fixed4 texColor = SampleSpriteTexture (IN.texcoord + fixed2(0,- _MainTex_TexelSize.y* _OutlineSize)) * IN.color; fixed4 c = _OutlineColor * texColor.a; return c; } ENDCG } //outline left Pass { Offset 1, 1 CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma shader_feature ETC1_EXTERNAL_ALPHA v2f vert(appdata_t IN) { return vert_outline(IN); } fixed4 frag(v2f IN) : SV_Target { fixed4 texColor = SampleSpriteTexture (IN.texcoord + fixed2(_MainTex_TexelSize.x* _OutlineSize,0)) * IN.color; fixed4 c = _OutlineColor * texColor.a; return c; } ENDCG } //outline right Pass { Offset 1, 1 CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma shader_feature ETC1_EXTERNAL_ALPHA v2f vert(appdata_t IN) { return vert_outline(IN); } fixed4 frag(v2f IN) : SV_Target { fixed4 texColor = SampleSpriteTexture (IN.texcoord + fixed2(-_MainTex_TexelSize.x* _OutlineSize,0)) * IN.color; fixed4 c = _OutlineColor * texColor.a; return c; } ENDCG }// Pass { Offset 0, 0 CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma shader_feature ETC1_EXTERNAL_ALPHA v2f vert(appdata_t IN) { v2f OUT; OUT.vertex = UnityObjectToClipPos(IN.vertex); OUT.texcoord = IN.texcoord; OUT.color = IN.color * _Color; #ifdef PIXELSNAP_ON OUT.vertex = UnityPixelSnap (OUT.vertex); #endif return OUT; } fixed4 frag(v2f IN) : SV_Target { fixed4 c = SampleSpriteTexture (IN.texcoord) * IN.color; c.rgb *= c.a; return c; } ENDCG } }} 总结：这个方案思路简单明了，很好理解，但可以看到这直接产生了5个DC，损耗过大，舍去，但也不失为一个方案在此做一个记录。 方案三：通过内收的方式描边，觉得也是个很好的思路，在这里做下记录 这里贴上代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182Shader &quot;Sprites/Outline&quot;{ Properties { [PerRendererData] _MainTex (&quot;Sprite Texture&quot;, 2D) = &quot;white&quot; {} _Color (&quot;Main texture Tint&quot;, Color) = (1,1,1,1) [Header(General Settings)] [MaterialToggle] _OutlineEnabled (&quot;Outline Enabled&quot;, Float) = 1 [MaterialToggle] _ConnectedAlpha (&quot;Connected Alpha&quot;, Float) = 0 [HideInInspector] _AlphaThreshold (&quot;Alpha clean&quot;, Range (0, 1)) = 0 _Thickness (&quot;Width (Max recommended 100)&quot;, float) = 10 [KeywordEnum(Contour, Frame)] _OutlineShape(&quot;Outline shape&quot;, Float) = 0 [KeywordEnum(Inside under sprite, Inside over sprite, Outside)] _OutlinePosition(&quot;Outline Position (Frame Only)&quot;, Float) = 0 _SolidOutline (&quot;Outline Color Base&quot;, Color) = (1,1,1,1) } SubShader { Tags { &quot;Queue&quot;=&quot;Transparent&quot; &quot;IgnoreProjector&quot;=&quot;True&quot; &quot;RenderType&quot;=&quot;Transparent&quot; &quot;PreviewType&quot;=&quot;Plane&quot; &quot;CanUseSpriteAtlas&quot;=&quot;True&quot; } Cull Off Lighting Off ZWrite Off Blend One OneMinusSrcAlpha Pass { CGPROGRAM #pragma vertex vert #pragma fragment frag #pragma multi_compile _ PIXELSNAP_ON #pragma exclude_renderers d3d11_9x #include &quot;UnityCG.cginc&quot; struct appdata_t { float4 vertex : POSITION; float4 color : COLOR; float2 texcoord : TEXCOORD0; }; struct v2f { float4 vertex : SV_POSITION; fixed4 color : COLOR; float2 texcoord : TEXCOORD0; }; fixed4 _Color; fixed _Thickness; fixed _OutlineEnabled; fixed _ConnectedAlpha; fixed _OutlineShape; //fixed _OutlineMode; fixed4 _SolidOutline; fixed _Weight; fixed _AlphaThreshold; v2f vert(appdata_t IN) { v2f OUT; OUT.vertex = UnityObjectToClipPos(IN.vertex); OUT.texcoord = IN.texcoord; OUT.color = IN.color * _Color; #ifdef PIXELSNAP_ON OUT.vertex = UnityPixelSnap (OUT.vertex); #endif return OUT; } sampler2D _MainTex; sampler2D _AlphaTex; float _AlphaSplitEnabled; uniform float4 _MainTex_TexelSize; //重新计算UV取样的 fixed4 SampleSpriteTexture (float2 uv) { float2 offsets; offsets = float2(_Thickness * 2, _Thickness * 2); float2 bigsize = float2(_MainTex_TexelSize.z, _MainTex_TexelSize.w); float2 smallsize = float2(_MainTex_TexelSize.z - offsets.x, _MainTex_TexelSize.w - offsets.y); float2 uv_changed = float2 ( uv.x * bigsize.x / smallsize.x - 0.5 * offsets.x / smallsize.x, uv.y * bigsize.y / smallsize.y - 0.5 * offsets.y / smallsize.y ); if(uv_changed.x &lt; 0 || uv_changed.x &gt; 1 || uv_changed.y &lt; 0 || uv_changed.y &gt; 1) { return float4(0, 0, 0, 0); } fixed4 color = tex2D (_MainTex, uv_changed);#if UNITY_TEXTURE_ALPHASPLIT_ALLOWED if (_AlphaSplitEnabled) color.a = tex2D (_AlphaTex, uv).r;#endif //UNITY_TEXTURE_ALPHASPLIT_ALLOWED return color; } //计算是否边为边缘 bool CheckOriginalSpriteTexture (float2 uv) { float thicknessX = _Thickness / _MainTex_TexelSize.z; float thicknessY = _Thickness / _MainTex_TexelSize.w; int steps = 100; float angle_step = 360.0 / steps; float alphaThreshold = _AlphaThreshold / 10; // check if the basic points has an alpha to speed up the process and not use the for loop bool outline = SampleSpriteTexture(uv + fixed2(0, +thicknessY)).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(0, -thicknessY)).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(+thicknessX, 0)).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(-thicknessX, 0)).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(+thicknessX * cos (3.14 / 4), -thicknessY * sin (3.14 / 4))).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(-thicknessX * cos (3.14 / 4), +thicknessY * sin (3.14 / 4))).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(-thicknessX * cos (3.14 / 4), -thicknessY * sin (3.14 / 4))).a &gt; alphaThreshold || SampleSpriteTexture(uv + fixed2(+thicknessX * cos (3.14 / 4), +thicknessY * sin (3.14 / 4))).a &gt; alphaThreshold; if(outline) return outline; for(int i = 0; i &lt; steps; i++) // high number and not a variable to avoid stupid compiler bugs { float angle = i * angle_step * 2 * 3.14 / 360; if( SampleSpriteTexture(uv + fixed2(thicknessX * cos(angle), thicknessY * sin(angle))).a &gt; alphaThreshold) { outline = true; break; } } return outline; } fixed4 frag(v2f IN) : SV_Target { fixed4 c = SampleSpriteTexture (IN.texcoord) * IN.color; c.rgb *= c.a; fixed4 outlineC = fixed4(0, 0, 0, 1); if(_OutlineEnabled != 0) { outlineC = _SolidOutline; if(_ConnectedAlpha != 0) { outlineC.a *= _Color.a; } outlineC.rgb *= outlineC.a; if( c.a == 0 &amp;&amp; CheckOriginalSpriteTexture(IN.texcoord)) { return outlineC; } return c; } return c; } ENDCG } }}","link":"/2022/08/27/SpriteOutline/"},{"title":"TheAdventureAndLegendOfTheEnchantedOre","text":"Once upon a time, in a small village nestled amidst a picturesque countryside, there was an unusual aroma lingering in the air. The odor (气味) of freshly baked bread wafted through the narrow streets, enticing the villagers with its irresistible scent. Among the villagers, there lived a young boy named Oliver, who possessed a unique talent. He had the ability to rub (擦) any two objects together and create sparks. This peculiar skill made him both admired and liable (有责任的) for any mishaps caused by his playful experiments. Oliver’s favorite place to indulge in his inventive endeavors was the old blacksmith’s forge (锻造场). He would spend hours there, tinkering with pieces of metal, shaping them into marvelous creations. His enthusiasm for craftsmanship was outward (向外的), and he dreamt of one day becoming a renowned artisan. One sunny day, while working in the forge, Oliver noticed a beam (横木) of light shining through a crack in the wall. Intrigued, he followed the beam to a hidden compartment where an ancient book lay untouched for centuries. The book contained intricate illustrations on how to reproduce (再现) mythical creatures thought to exist only in fables (寓言). Excitement filled Oliver’s figure (身影) as he flipped through the pages, studying the detailed instructions on how to bring these creatures to life. He discovered that the key ingredient for their existence was a rare mineral called enchanted ore (附魔矿石), which could only be found deep within the heart of a treacherous mountain. Determined to embark on this extraordinary journey, Oliver made preparations for his expedition. With a slam (砰) of his hammer, he crafted a sturdy accent (重音) to aid him in climbing the rugged terrain. His wrinkled (起皱的) hands meticulously packed supplies, knowing the path ahead would be challenging. As the sun began to hatch (孵化) over the horizon, Oliver set foot on his quest, armed with a map and fueled by his unwavering spirit. He navigated through dense forests, crossed swift rivers, and climbed treacherous cliffs with the agility of a seasoned explorer. Finally, after days of arduous travel, Oliver reached the mountain’s peak. He could hear the distant sound of grinding (磨碎) rocks as he approached the entrance to the enchanted ore mine. With caution and anticipation, he initiated (开始) his descent into the depths of the earth. The mine revealed a vast cavern filled with a shallow (浅的) pool of sparkling water. Resting on its surface were fragments of enchanted ore, glistening like precious gems. Oliver carefully collected the mineral, knowing it held the power to bring his fabled creatures to life. With the enchanted ore in his possession, Oliver made his way back to the village, his heart filled with a mix of accomplishment and curiosity. Upon his return, he gathered the villagers and shared his incredible tale. He described the creatures he had seen in the ancient book, captivating their imagination. Using the enchanted ore, Oliver followed the book’s instructions to recreate the creatures. As he chanted the necessary incantations, the air crackled with energy, and before their eyes, the mythical beings emerged from the realm of imagination into reality. A majestic phoenix soared through the sky, while a wise dragon roamed the countryside, guarding the village with its fiery breath. The village became a hub of biology (生物学) enthusiasts, as scholars from far and wide flocked to study these remarkable creatures. Oliver’s name echoed through the ages as the young boy who resisted the temptation (诱惑) to keep the enchanted ore for himself and instead shared its magic with the world. And so, the once ordinary village became an extraordinary place, where the extraordinary happened as if by automatic (自动的) design. Oliver’s courage, creativity, and unwavering spirit had forever changed the fate of the village and its inhabitants, leaving behind a legacy that would be told in tales for generations to come. 中文从前，在一个坐落在风景如画的乡村的小村庄里，空气中弥漫着一种不寻常的气味。新鲜烤面包的气味飘过狭窄的街道，用其诱人的香气吸引着村民们。 在村子里住着一个名叫奥利弗的年轻男孩，他有着独特的天赋。他可以擦拭任何两个物体，然后产生火花。这种奇特的技能使他备受钦佩，但也使他有责任（有责任的）对他的玩乐性实验造成的任何意外负责。 奥利弗最喜欢从事他的发明工作的地方是老铁匠的锻造场。他会在那里待上几个小时，修补金属碎片，将它们塑造成奇妙的作品。他对手艺的热情向外散发着，他梦想有一天成为一名著名的工匠。 一个阳光明媚的日子，当他在锻造场工作时，奥利弗注意到一束光线从墙上的裂缝中射入。他好奇地跟着光线，发现了一个隐藏的隔间，里面有一本古老的书，已经被搁置了几个世纪。这本书上有关于再现寓言中传说中生物的复杂插图。 奥利弗翻阅着书页，兴致勃勃地学习如何让这些生物重新活过来。他发现这些生物存在的关键是一种稀有的矿石，被称为附魔矿石，只能在危险的山脉深处找到。 为了踏上这不寻常的旅程，奥利弗开始准备他的探险。他用锤子砰地一声，打造了一个坚固的重音，帮助他攀爬崎岖的地形。他皱纹斑驳的手仔细地整理着供给品，因为他知道前方的道路将充满挑战。 当太阳开始孵化出地平线时，奥利弗踏上了他的任务，带着一张地图和坚定的精神。他穿过茂密的森林，越过湍急的河流，用一名经验丰富的探险家的敏捷攀爬险峻的悬崖。 终于，在数天的艰苦旅行后，奥利弗抵达了山峰。他听到远处石头的磨碎声，当他走近附魔矿石矿井的入口时。小心翼翼地收集着这种矿石，他知道它拥有让传说中的生物重生的力量。 拥有附魔矿石后，奥利弗回到村庄，心中充满了成就感和好奇心。回到村子后，他召集了村民，与他们分享了他难以置信的故事。他描述了古老书中的生物，引起了他们的想象。 利用附魔矿石，奥利弗按照书中的指示重新创造了这些生物。当他吟唱必要的咒语时，空气中充满了能量，在他们眼前，这些神秘的生物从想象的领域走进了现实。一只雄伟的凤凰飞翔在天空中，一条智慧的龙在乡间漫游，用其火焰呼吸守护着村庄。 村庄成为生物学爱好者的聚集地，因为来自各地的学者涌来研究这些非凡的生物。奥利弗的名字在历代传颂，作为一个年轻的男孩，他抵制了诱惑将附魔矿石留给自己，而是将其魔力与世界分享。 于是，这个曾经平凡的村庄变成了一个非凡的地方，非凡的事情似乎如自动（自动的）般发生。奥利弗的勇气、创造力和坚定不移的精神永远改变了村庄和居民的命运，留下了一个代代相传的传奇。 单词odor - 气味rub - 擦拭liable - 有责任的forge - 锻造outward - 向外的beam - 光束，横梁reproduce - 再现，繁殖figure - 数字，图形，人物ore - 矿石fable - 寓言slam - 猛力关闭，砰然关闭accent - 口音，重音wrinkle - 皱纹hatch - 孵化preposition - 介词grind - 磨碎initiate - 开始，发起shallow - 浅的pigeon - 鸽子gaze - 凝视biology - 生物学temptation - 诱惑automatic - 自动的","link":"/2023/07/27/TheAdventureAndLegendOfTheEnchantedOre/"},{"title":"Sprite Outlines2","text":"效果如下： 代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899Shader &quot;Tutorial/049_SpriteOutline&quot;{ Properties{ _Color (&quot;Tint&quot;, Color) = (0, 0, 0, 1) _OutlineColor (&quot;OutlineColor&quot;, Color) = (1, 1, 1, 1) _OutlineWidth (&quot;OutlineWidth&quot;, Range(0, 1)) = 1 _MainTex (&quot;Texture&quot;, 2D) = &quot;white&quot; {} } SubShader{ Tags{ &quot;RenderType&quot;=&quot;Transparent&quot; &quot;Queue&quot;=&quot;Transparent&quot; } Blend SrcAlpha OneMinusSrcAlpha ZWrite off Cull off Pass{ CGPROGRAM #include &quot;UnityCG.cginc&quot; #pragma vertex vert #pragma fragment frag sampler2D _MainTex; float4 _MainTex_ST; float4 _MainTex_TexelSize; fixed4 _Color; fixed4 _OutlineColor; float _OutlineWidth; struct appdata{ float4 vertex : POSITION; float2 uv : TEXCOORD0; fixed4 color : COLOR; }; struct v2f{ float4 position : SV_POSITION; float2 uv : TEXCOORD0; float3 worldPos : TEXCOORD1; fixed4 color : COLOR; }; v2f vert(appdata v){ v2f o; o.position = UnityObjectToClipPos(v.vertex); o.worldPos = mul(unity_ObjectToWorld, v.vertex); o.uv = TRANSFORM_TEX(v.uv, _MainTex); o.color = v.color; return o; } float2 uvPerWorldUnit(float2 uv, float2 space){ float2 uvPerPixelX = abs(ddx(uv)); float2 uvPerPixelY = abs(ddy(uv)); float unitsPerPixelX = length(ddx(space)); float unitsPerPixelY = length(ddy(space)); float2 uvPerUnitX = uvPerPixelX / unitsPerPixelX; float2 uvPerUnitY = uvPerPixelY / unitsPerPixelY; return (uvPerUnitX + uvPerUnitY); } fixed4 frag(v2f i) : SV_TARGET{ //get regular color fixed4 col = tex2D(_MainTex, i.uv); col *= _Color; col *= i.color; float2 sampleDistance = uvPerWorldUnit(i.uv, i.worldPos.xy) * _OutlineWidth; //float2 sampleDistance = _MainTex_TexelSize.xy * _OutlineWidth; //sample directions #define DIV_SQRT_2 0.70710678118 float2 directions[8] = {float2(1, 0), float2(0, 1), float2(-1, 0), float2(0, -1), float2(DIV_SQRT_2, DIV_SQRT_2), float2(-DIV_SQRT_2, DIV_SQRT_2), float2(-DIV_SQRT_2, -DIV_SQRT_2), float2(DIV_SQRT_2, -DIV_SQRT_2)}; //generate border float maxAlpha = 0; for(uint index = 0; index&lt;8; index++){ float2 sampleUV = i.uv + directions[index] * sampleDistance; maxAlpha = max(maxAlpha, tex2D(_MainTex, sampleUV).a); } //apply border col.rgb = lerp(_OutlineColor.rgb, col.rgb, col.a); col.a = max(col.a, maxAlpha); return col; } ENDCG } }} 原理：这种方法用于为纹理创建轮廓或边框效果，特别适用于风格化渲染或突出场景中的某些元素。该过程涉及在UV坐标周围的多个点采样纹理，并使用Alpha通道信息来确定轮廓。以下是该方法的逐步分解： 为目标对象创建一个新的着色器或材质，以便在其上应用轮廓效果。 在着色器中，根据原始UV坐标对纹理进行采样。这可以通过使用类似HLSL中的tex2D或GLSL中的texture2D函数来实现。 为Alpha通道设置阈值，以区分可见和不可见像素。 在原始UV坐标周围定义一个内核或一组相邻点，以便对纹理进行采样。这可以通过为U和V坐标设置偏移量来实现。 遍历相邻点，并在每个点处对纹理进行采样。 将每个样本的Alpha值与阈值进行比较。如果Alpha值高于阈值，则记住找到的最高Alpha值。 遍历所有相邻点后，检查原始像素是否不可见（即其Alpha值低于阈值），并且在相邻像素中找到的最高Alpha值高于阈值。 如果满足这两个条件，则通过将输出像素颜色设置为所需的轮廓颜色（通常为黑色或与原始纹理形成对比的颜色），并将Alpha值设置为1（完全不透明）来填充轮廓。 否则，使用原始纹理颜色和Alpha值作为输出像素。 这种方法将通过检测原始像素及其相邻像素之间的Alpha通道值差异，在纹理的可见部分周围创建轮廓或边框效果。当纹理的Alpha通道中可见和不可见像素之间存在明显区别时，轮廓会更加突出。 4、遍历相邻点，并在每个点处对纹理进行采样。主要通过这句 12345#define DIV_SQRT_2 0.70710678118float2 directions[8] = {float2(1, 0), float2(0, 1), float2(-1, 0), float2(0, -1), float2(DIV_SQRT_2, DIV_SQRT_2), float2(-DIV_SQRT_2, DIV_SQRT_2), float2(-DIV_SQRT_2, -DIV_SQRT_2), float2(DIV_SQRT_2, -DIV_SQRT_2)}; 在片段函数中，我们首先创建一个方向数组，用于存储我们希望进行采样的方向。你可以牺牲一些速度来获得更多的灵活性，通过使用sin和cos函数来获得这些方向，但这取决于你的选择。我选择在8个方向上进行采样，包括四个主要方向以及对角线方向。重要的是，对角线方向也应该有长度1，如果我们只使用(1, 1)，它们的长度将是sqrt(2)（通过勾股定理很容易得到这个结果，即sqrt(1² + 1²)），我们需要将每个分量除以sqrt(2)，即使用1 / sqrt(2)，这样就可以了。 上面的代码定义了一个名为directions的数组，它包含了8个方向。这些方向分别是上、下、左、右以及对角线方向。DIV_SQRT_2是1除以sqrt(2)的结果，用于计算对角线方向的单位向量。这样，我们可以在这8个方向上对纹理进行采样，以实现轮廓效果。 1、计算轮廓宽度1、以纹素大小为缩放1float2 sampleDistance = _MainTex_TexelSize.xy * _OutlineWidth; 把上这句开启： 这句代码是用于计算轮廓宽度的实际采样距离，以纹理坐标（UV坐标）为单位。我们通过将纹理的纹素大小（_MainTex_TexelSize.xy）与轮廓宽度属性（_OutlineWidth）相乘来实现这一点。 _MainTex_TexelSize.xy：这是一个包含纹理的纹素大小（宽度和高度）的二维向量。它表示一个纹素在UV空间中所占的尺寸。_MainTex_TexelSize.x表示一个纹素在U轴上的尺寸，_MainTex_TexelSize.y表示一个纹素在V轴上的尺寸。这个变量是由Unity自动生成的，对应于_MainTex纹理。 _OutlineWidth：这是一个浮点数，表示轮廓的宽度，以纹理像素为单位。这个值可以在Unity的材质面板上调整，范围为0到10。 将这两个值相乘，我们可以得到一个二维向量sampleDistance，它表示轮廓宽度在UV空间中的实际采样距离。这样，在后面的循环中，我们就可以使用这个距离来计算周围采样点的UV坐标，从而实现不同宽度的轮廓效果。 2、以世界空间宽度为缩放1float2 sampleDistance = uvPerWorldUnit(i.uv, i.worldPos.xy) * _OutlineWidth; ​ 只需要获取每个世界距离的uv距离，然后像目前使用纹素大小那样将其与轮廓宽度相乘，那么让我们为此编写一个函数。可以通过屏幕空间偏导数（更为人熟知的ddx，ddy和fwidth）来计算这个值。 偏导数使我们能够获得每个屏幕像素的uv变化以及每个屏幕像素的世界空间位置变化。我们必须获得uv变化的绝对值，以免意外获得负值，同时还要获得世界位置变化的长度，以便在相机旋转时获得正确的距离。 通过这些值，我们可以通过将每像素的uv除以每像素的单位数，得到x和y轴上的每单位uv值。在x和y方向上获取这些值后，我们只需将这两个值相加并返回它。 123456789float2 uvPerWorldUnit(float2 uv, float2 space){ float2 uvPerPixelX = abs(ddx(uv)); float2 uvPerPixelY = abs(ddy(uv)); float unitsPerPixelX = length(ddx(space)); float unitsPerPixelY = length(ddy(space)); float2 uvPerUnitX = uvPerPixelX / unitsPerPixelX; float2 uvPerUnitY = uvPerPixelY / unitsPerPixelY; return (uvPerUnitX + uvPerUnitY);} 这个函数接受两个输入参数：uv（纹理坐标）和space（世界空间位置）。它首先计算每个屏幕像素的uv变化（uvPerPixelX和uvPerPixelY），然后计算每个屏幕像素的世界空间位置变化（unitsPerPixelX和unitsPerPixelY）。接着，我们可以通过将每像素的uv变化除以每像素的世界空间位置变化来计算x和y轴上的每单位uv值（uvPerUnitX和uvPerUnitY）。最后，将这两个值相加并返回结果。 通过这个函数，我们可以根据世界空间宽度计算轮廓宽度，这样一来，当相机旋转或者距离变化时，轮廓宽度将保持一致。 7、使用最大Alpha使判断边沿使用最大Alpha值来判断边缘的方法基于这样一个观察：在边缘处，一个低Alpha值（透明或半透明）的像素周围通常至少有一个较高Alpha值（不透明）的像素。在这种情况下，我们将遍历周围的采样点，并寻找最大的Alpha值。边缘检测的关键在于比较原始像素的Alpha值和周围采样点的最大Alpha值。 以下是整个过程的详细说明： 遍历周围的采样点，并找到最大Alpha值（maxAlpha）。 使用lerp()函数根据原始像素的Alpha值在原始颜色（col.rgb）和轮廓颜色（_OutlineColor.rgb）之间进行插值。当原始像素的Alpha值较低时（接近透明），插值结果将更接近轮廓颜色。 将col.a设置为max(col.a, maxAlpha)。这样，如果原始像素的Alpha值较低（透明或半透明），而周围采样点的最大Alpha值较高（不透明），则边缘处的像素将具有更高的Alpha值。 通过这种方法，我们可以找到边缘，并在边缘处使Alpha值变为不透明。这样一来，即使原始像素的Alpha值较低，轮廓部分仍然可见。这种方法的关键在于比较原始像素的Alpha值和周围采样点的最大Alpha值，从而识别出边缘并在边缘处生成可见的轮廓。","link":"/2023/05/07/Sprite-Outlines2/"},{"title":"判断点是否在平面内","text":"射线法射线法是一种常用于判断点是否在多边形内部的方法。以下是如何使用射线法的示例： 假设我们有一个非凸多边形P，由顶点A(0,0)，B(4,0)，C(4,4)，D(2,2)和E(0,4)组成。我们想判断一个点F(1,1)是否在这个多边形内。 选择射线: 我们可以从点F发出一条水平射线，向右延伸。选择水平或垂直射线通常会简化计算，但理论上射线可以朝任何方向。 计算交点: 现在我们计算这条射线与多边形的边交叉的次数。要注意的是，如果射线与多边形的顶点相交，我们只计算它一次（除非这个顶点是多边形的凹点，这种情况较为复杂，通常需要特别处理）。 F与AB相交: 否 F与BC相交: 否 F与CD相交: 是 F与DE相交: 否 F与EA相交: 否 所以，射线与多边形交叉了1次。 判断奇偶: 因为交叉次数是奇数，所以点F位于多边形P的内部。 如果我们选取一个明显在多边形外部的点G(5,5)，并重复上述过程，我们会发现射线与多边形交叉了0次（偶数次），所以点G在多边形外部。 请注意，射线法有一些特殊情况，可能需要特别处理。例如，如果射线与多边形的一个凹顶点相交，或者与多边形的边完全重合，可能需要特别的逻辑来正确处理。不过在大多数情况下，射线法是一种简单有效的判断点是否在多边形内部的方法。 使用Unity实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546using UnityEngine;public class PointInPolygonChecker : MonoBehaviour{ public GameObject objectToCheck; // 你想检查的对象 private PolygonCollider2D polygonCollider; void Start() { polygonCollider = GetComponent&lt;PolygonCollider2D&gt;(); } void Update() { Vector2[] vertices = polygonCollider.GetPath(0); // 获取多边形的第一条路径的顶点 Vector2 pointToCheck = objectToCheck.transform.position; // 获取对象的位置 if (IsPointInPolygon(pointToCheck, vertices)) { Debug.Log(&quot;Point is inside the polygon!&quot;); } else { Debug.Log(&quot;Point is outside the polygon!&quot;); } } bool IsPointInPolygon(Vector2 point, Vector2[] vertices) { bool inside = false; int j = vertices.Length - 1; for (int i = 0; i &lt; vertices.Length; i++) { if ((vertices[i].y &lt; point.y &amp;&amp; vertices[j].y &gt;= point.y || vertices[j].y &lt; point.y &amp;&amp; vertices[i].y &gt;= point.y) &amp;&amp; (vertices[i].x &lt;= point.x || vertices[j].x &lt;= point.x)) { inside ^= (vertices[i].x + (point.y - vertices[i].y) / (vertices[j].y - vertices[i].y) * (vertices[j].x - vertices[i].x) &lt; point.x); } j = i; } return inside; }} 代码分析在这个代码中，添加了一个公共字段objectToCheck，你以在Inspector中将其设置为想要检查的游戏对象。然后，在Update方法中，使用该对象的位置作为要检查的点。 请注意，这里假设多边形和要检查的对象都位于同一个平面内，且objectToCheck的位置的z坐标与多边形的z坐标相同（或至少足够接近，以便在2D空间内进行合适的比较）。如果这些假设不成立，可能需要进一步修改代码来正确处理3D空间中的坐标。 12if ((vertices[i].y &lt; point.y &amp;&amp; vertices[j].y &gt;= point.y || vertices[j].y &lt; point.y &amp;&amp; vertices[i].y &gt;= point.y) &amp;&amp; (vertices[i].x &lt;= point.x || vertices[j].x &lt;= point.x)) 这个if条件包含了两个主要的部分 这个if条件包含了两个主要的部分，我们可以按照你给的示例代码逐个解释它们。 检查y坐标是否在边界范围内: vertices[i].y &lt; point.y &amp;&amp; vertices[j].y &gt;= point.y：这部分检查当前边界的一个顶点是否在点的下方，而另一个顶点是否在点的上方。 vertices[j].y &lt; point.y &amp;&amp; vertices[i].y &gt;= point.y：这部分检查当前边界的一个顶点是否在点的上方，而另一个顶点是否在点的下方。 用更通俗的话说，这部分代码检查边界是否与点的水平线相交。 2.检查x坐标是否小于边界之一的x坐标: ​ 如果一个线段的两个端点都在所要检查的点的右侧，那么它与从该点向左延伸的水平线不会相交。但是，如果线段的至少一个端点在所要检查的点的左侧或与其垂直对齐，那么线段可能与从该点向左延伸的水平线相交。 ​ 这个条件用于过滤掉那些明显不会与从点向左延伸的水平线相交的线段，从而减少了不必要的计算。只有当线段至少有一个端点在所要检查的点的左侧时，才会进一步考虑该线段，并使用先前解释的数学表达式来确定线段是否实际与水平线相交，并据此更新inside变量的值。 1inside ^= (vertices[i].x + (point.y - vertices[i].y) / (vertices[j].y - vertices[i].y) * (vertices[j].x - vertices[i].x) &lt; point.x); 这行代码中使用了一些数学和编程技巧，让我们逐个分解。 计算交点的x坐标: (point.y - vertices[i].y) / (vertices[j].y - vertices[i].y)计算点的y坐标与线段两端之间的相对位置。 然后，乘以(vertices[j].x - vertices[i].x)得到与y坐标相对应的x坐标的差异。 最后，加上vertices[i].x得到交点的x坐标。 比较交点的x坐标与点的x坐标: 通过比较交点的x坐标和点的x坐标，我们可以知道交点是在点的左边还是右边。 如果交点在点的左边，则表达式的结果为true，否则为false。 使用异或（XOR）操作更新inside变量: ^=是异或赋值操作符。异或是一个逻辑操作，如果两个操作数不同，则结果为true，否则为false。 在这种情况下，如果交点在点的左边，则inside的值会切换。如果交点在点的右边，inside的值不变。 因此，如果交叉次数是奇数，inside最终为true；如果是偶数，则为false。 简单地说，这行代码计算了从点向左延伸的水平线与多边形边界的交点的x坐标，并检查交点是否在点的左侧。然后，它使用异或操作来计算交叉次数，并据此判断点是否在多边形内部。","link":"/2023/07/30/%E5%88%A4%E6%96%AD%E7%82%B9%E6%98%AF%E5%90%A6%E5%9C%A8%E5%B9%B3%E9%9D%A2%E5%86%85/"},{"title":"读《高效能人人士的七个习惯》","text":"习惯二：以终为始撰写个人使命宣言清晰地定义个人的核心价值观、目标和目的，并将其表达出来的一种工具。通过撰写个人使命宣言，人们可以明确自己的生活目标、愿景和价值观，并以此为指导在各个领域做出决策和行动。通过表达和想像来加强个人价值观的理解和内化。反复思考和表达自己的核心价值观，并在心中进行反复演练，以达到潜移默化的转变。 个人使命宣言通常涵盖以下方面： 个人价值观和原则：明确自己的核心价值观和道德准则，例如诚实、正直、勇敢等。 长期目标和愿景：设定个人追求的长期目标和愿景，对未来有明确的方向和目标。 贡献和影响力：阐述自己希望通过自己的行为和工作对他人和社会产生的积极影响。 个人使命陈述：将以上内容整合成一个简洁而有力的陈述，概括自己的个人使命和意义。 撰写个人使命宣言有助于个人的自我认知和目标定位，可以提供清晰的方向，使个人在日常生活中更加有目标和意义。它也可以帮助人们更好地理解自己的价值观和优先级，并在面临抉择时做出更明智的决策。 思考：读到这里时，感觉很有意思，在我工作生活中，特别是作为一个前端的程序员，工作，重复的工作占据了生活的大部分时间，当一有时候空闲下来就会感觉到很迷茫，不知道做什么，头脑经过长时间的工作也变得迟钝、很累想不出自己应该做什么。此时这些碎片的空余时间就会被无目地的刷刷论坛和短视频时里面消耗掉了。但与此同时作为一个996的前端工作者，是没有时间或很少会有成块的时间的。所以反复思考，反复演练，以达到潜移默化，对自己时间的见缝插针就变得尤其重要。 练习方式练习表达和内化个人的核心价值观是一个逐渐深化和持续的过程。以下是一些方法和建议，可以帮助开始实践这个过程： 自省和反思：花时间自省，思考自己真正重要的事物和价值观。问自己一些关键问题，例如什么是对你来说最重要的？你希望在生活中实现什么？这些问题可以帮助你更好地理解自己的核心价值观。 撰写个人使命宣言：将你的核心价值观、长期目标和愿景写成一个简洁而有力的陈述。这个宣言可以作为你的指导原则，帮助你在决策和行动中保持一致性。 反复阅读和思考：将个人使命宣言作为参考，反复阅读和思考它的含义和意义。在日常生活中，抽出时间来仔细阅读和思考它，让这些价值观深入你的思维和意识。 想象和演练：在心中想象自己以这些价值观为指导的情景和行为。反复演练这些场景，想象自己如何应对和表现。通过想象和演练，你可以加强自己与这些价值观的联系，逐渐将它们融入到你的行为中。 实践和反馈：在日常生活中积极应用你的核心价值观。将它们应用于决策、行为和与他人的互动中。持续关注自己的实践，并反思自己的行为是否符合你的价值观。从反馈中学习和成长，并不断调整自己的行为。 记住，这个过程需要时间和持续的努力。通过不断地练习和实践，你可以逐渐加深对自己的价值观的理解，让它们在你的生活中起到更大的作用。 根据角色的不同，我们可能会有不同的使命或价值观。一个人在不同的角色中扮演不同的身份，例如作为家庭成员、职业人士、社区成员等，这些角色对应着不同的责任和期望。在每个角色中，你可以思考和界定相应的使命和价值观。例如，作为一个家庭成员，你的使命可能是关爱和支持家人，维系家庭的和谐；作为职业人士，你的使命可能是努力工作，为公司和社会做出贡献；作为社区成员，你的使命可能是参与社区活动，关注社会问题并积极参与改变。 通过对每个角色进行思考和界定，你可以明确每个角色的核心价值观和使命陈述。这有助于你在不同的角色中保持一致性，并更好地履行各个角色所带来的责任和使命。在实践中，要注意不同角色之间的平衡和协调。有时候，不同的角色可能会产生冲突或优先级的竞争，需要灵活处理和权衡。关键是要确保各个角色之间的关系相互支持和促进，使整个生活更加和谐和有意义。 习惯四：双赢思维当谈到双赢思维时，它是指一种心态和方法，旨在寻求和创造双方都能从中受益的解决方案。以下是对双赢思维的总结： 合作而非竞争：双赢思维强调合作和协作，而非单纯的竞争。它鼓励人们以合作的方式与他人合作，寻求共同利益和共同成长，而不是通过竞争争取个人利益。 积极寻求解决方案：双赢思维的关键在于寻求解决方案，让各方都能获得满意的结果。它要求人们放下对抗和争斗的心态，积极探索创造性的解决方案，以满足各方的需求和利益。 尊重和理解他人：双赢思维强调对他人的尊重和理解。它鼓励人们倾听他人的观点和利益，尊重他人的权益和需要，从而建立积极的合作关系。 长期的眼光：双赢思维注重长期的发展和关系。它认识到通过建立良好的合作关系和互相支持，可以实现长期的持续性双赢局面，而不是短期的权宜之计。 创造价值：双赢思维强调创造共同的价值。它鼓励人们思考如何通过合作和协作，为各方带来更大的价值，从而推动共同的成功和成长。 总而言之，双赢思维是一种积极的心态和方法，它通过合作、寻求解决方案、尊重他人、长期发展和创造共同价值，致力于实现各方的共同利益和持续的成功。 如果无法实现双赢，那么放弃是一个可选的选择。这意味着在某些情况下，如果无法找到满足双方利益的解决方案，放弃当前的选择可能会更有益。放弃并不意味着放弃所有目标或牺牲自己的需要，而是指意识到当前的选择或争议不具备双赢的潜力，从而寻找更合适的解决方案或机会。这样做有助于避免陷入僵局、冲突或不健康的关系。 放弃的决策可能涉及一些权衡和考量，例如： 长远利益：评估当前选择是否会对个人或团体的长远利益产生负面影响。如果发现持续追求当前选择会导致不可弥补的损失或伤害，那么放弃可能是更明智的选择。 价值观和原则：将当前选择与自己的价值观和原则进行对比。如果当前选择违背了个人的核心价值观或原则，并且无法找到妥协或调和的方式，那么放弃可能更符合自己的内心需求。 替代机会：评估是否存在更好的替代机会或选择。有时候，放弃当前选择可能为更好的机会或解决方案打开了门，能够带来更大的利益和满足。 需要注意的是，放弃并不是一种逃避责任或避免困难的方式。它是在认识到当前选择无法实现双赢或对个人利益造成不利影响时，做出明智的决策。通过放弃，你为自己创造了更多的机会，寻找更符合自身价值观和目标的路径。 思考这个观念乍一看有点空洞，假大空想感觉，对这些东西泛泛而谈，但似乎没有现实上的操作意义，什么都是理想上的太完美的想当然而以。但细想一下其实这个心态也确实可以运用到生活、工作、家庭中。如： 感情中：感情中是没有输赢的，当然也没有赢输。如果非要争个高低只有两败具伤，大家都不快乐。 工作中：我时常想如果我在公司中做多一点，花的时间多一点，那我的时间是不是就会少一点。但不花心思多一点，工作出来的结果永远都是差强人意，明明可以做到90分的，却只做80分出来自己满意，公司也不满意，甚至影响到别人对本人的判断，这又真的好吗。 等一下，我在公司工作，在工作时间发现了有些地方不完美，去完善它，公司给我了薪资，我做好工作，这本是我的本职上的事情，理所当然的事情啊。 为什么我会纠结呢？我纠结是忘记了什么是第一，什么是第二了。上班时间肯定工作第一，不是吗？ 我的个人使命： 健康第一 家庭第二 保持专注，注重效率，关注当下 去尝试，偿试所能想到的一切，人生不能重来，无所畏惧 保持成长，坚持阅读 6年挣100万，一年存15万，一个月存12k 与人相处，想其所想，思其所虑","link":"/2023/06/24/%E8%AF%BB%E3%80%8A%E9%AB%98%E6%95%88%E8%83%BD%E4%BA%BA%E4%BA%BA%E5%A3%AB%E7%9A%84%E4%B8%83%E4%B8%AA%E4%B9%A0%E6%83%AF%E3%80%8B/"},{"title":"读《掌控习惯》","text":"如何培养好习惯第一定律：让它显而意见 填写习惯记分卡：记录下当前习惯，并持续留意它们。 应用执行意图：在特定时间和地点明确制定执行某项习惯的行为：“我将于【时间】在【地点】【行为】”。 应用习惯叠加：将新的习惯与已有的习惯相结合：“继【当前习惯】之后，我将会【新习惯】”。 设计你的环境：确保良好习惯的提示在你的环境中清晰明了。 第二定律：让它更具吸引力 利用对奖励的期待心理，与喜好绑定：为良好习惯设置适当的奖励机制，增加其吸引力。 第四定律：让它令人愉悦 即时满足、有回报的行为会被重复，避免受到惩罚的动作。 顺应人性，给能为长远带来回报的事情添加一点即时快乐，给不良的事情添加一点痛苦。 天天保持好习惯的习惯跟踪法： 创建视觉提示，提醒你采取行动。 建立内在激励机制，清楚地看到你的进步轨迹，并且不想失去它。 每当记录下一个成功的习惯实例时，享受到满足感。 习惯追踪提供了视觉证据，证明你正在塑造成为你想成为的那类人，这本身就是一种令人愉悦的即时、内在满足的形式。 如何破除坏习惯：第一定律反用：让它脱离视线 降低坏习惯的出现频率，将其提示清除出你的环境。 第二定律反用：让它缺乏吸引力第三定律反用：让它难以施行 增加与不良行为的相关阻力，提高戒除坏习惯的难度。 第四定律反用：让它令人厌恶通过遵循以上方法，你将能够更好地培养良好习惯，同时有效地摆脱坏习惯。良好习惯的养成需要持之以恒的努力和耐心，但只要坚持下去，你将在未来的生活中获得积极的回报，成为更好的自己。","link":"/2023/07/27/%E8%AF%BB%E3%80%8A%E6%8E%8C%E6%8E%A7%E4%B9%A0%E6%83%AF%E3%80%8B/"}],"tags":[{"name":"shader","slug":"shader","link":"/tags/shader/"},{"name":"English","slug":"English","link":"/tags/English/"},{"name":"openGL","slug":"openGL","link":"/tags/openGL/"},{"name":"match","slug":"match","link":"/tags/match/"}],"categories":[{"name":"shader","slug":"shader","link":"/categories/shader/"},{"name":"英文","slug":"英文","link":"/categories/%E8%8B%B1%E6%96%87/"},{"name":"OpenGL","slug":"OpenGL","link":"/categories/OpenGL/"},{"name":"match","slug":"match","link":"/categories/match/"},{"name":"书籍阅读","slug":"书籍阅读","link":"/categories/%E4%B9%A6%E7%B1%8D%E9%98%85%E8%AF%BB/"}],"pages":[{"title":"categories","text":"","link":"/categories/index.html"}]}